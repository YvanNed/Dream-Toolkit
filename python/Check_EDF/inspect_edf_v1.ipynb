{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12bcc77e-a10a-441b-b8e9-33006dd75aee",
   "metadata": {},
   "source": [
    "# Inspect export parameters from .edf files of an EEG database \n",
    "This notebook allows you to inspect the parameters of your .edf EEG database. \\\n",
    "It does not load and inspect the quality of your data. \\\n",
    "It helps you identify if you need to re-export some participant's data (due to poor signal resolution or clipping, as explained later). \\\n",
    "It provides information that helps analyze your dataset (such as the different channel labels). \n",
    "\n",
    "---\n",
    "EDF (European Data Format) is a standard format for storing multichannel biological and physical signals: https://www.edfplus.info/. \\\n",
    "It was first published in 1992, and an upgraded version was released in 2003 (adding discontinuous recordings handling, annotations, stimuli, and events in a UTF-8 format). \\\n",
    "It is a compressed 16-bit format, meaning that each measured data point can take 2^16 values between the minimum and maximum values that you set at exportation. \\\n",
    "The min/max values correspond to the dynamic range of your data.\n",
    "\n",
    "---\n",
    "At the exportation in the .edf format (with software like Profusion from Compumedics), many parameters need to be set per recorded channels, such as channels' label, sampling frequency, filtering, units, and dynamic range. \\\n",
    "Exporting as .edf format is tedious and time-consuming, so mistakes in parameters can easily be made.  \\\n",
    "To avoid making mistakes, there is the possibility of implementing routines within some software (insert a link on how to make a routine in Compumedics). \\\n",
    "Inspecting those parameters can also be necessary if you work on an already existing dataset, to make sure that every participant's data is exploitable, specifically if the data comes from multiple sleep clinics. \n",
    "\n",
    "---\n",
    "This notebook reads information from the .edf files, instead of loading the data and relying on existing packages. \\\n",
    "Existing packages, such as PYEDFLIB or MNE, are either too rigid (not able to read some data) or do not return all the information (such as boundaries of dynamic range, filtering parameters, etc).\\\n",
    "\\\n",
    "**To use this notebook, read each text box (called markdown cells in Jupyter notebook), run its associated code box (code cell), and read the output below.**\\\n",
    "To run a cell, select the cell and either click on \"Run\" and \"Run Selected Cell\" in the menu bar, or press \"Shift+Enter\". \\\n",
    "_The notebook will save summary tables as .tsv files (file format easy to read with Excel and to import in Python script) so that you can visually inspect (or reload later) if needed._ \\\n",
    "Those summaries will be stored in a summary folder within the study folder. \\\n",
    "\\\n",
    "This notebook is organized into 4 sections (with a section 0 to prepare your notebook):\n",
    "1. Select your study folder, extract the data's information, and return general information\n",
    "2. Inspect EEG channels\n",
    "3. Inspect EOG channels\n",
    "4. Inspect ECG channels\n",
    "\n",
    "Once you are done with one section, you can reduce it by pressing the down arrow on the left of the section title, to improve the readability.\n",
    "\n",
    "---\n",
    "This notebook was developed on the ICEBERG database and tested on APOMORPHEE (from Noémie's internship).  \\\n",
    "last update 28/07/2025, YN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d45c0-237c-4460-9a7c-1f7e88f5c88d",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px; background-color:black; border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316eaf2b-5591-4698-968d-5117df3f8b13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0. Import packages and define custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d7e8e-b926-4914-97ee-92f4b39567fc",
   "metadata": {},
   "source": [
    "In this notebook (and the majority of Python scripts), we use packages that contain pre-defined functions to perform our operations. \\\n",
    "The code cell below loads the packages required for this notebook and defines custom functions that we will use. \\\n",
    "If you have already installed all the packages, you will get the message ``Packages and functions successfully imported``. \\\n",
    "\\\n",
    "If you are missing one package, you will get an error ``ModuleNotFoundError: No module named 'my_package'``.\\\n",
    "To install the missing package, there are two solutions:\n",
    "1. Install within Jupyter notebook:\n",
    "    - open a new cell (click on \"+\" in the top-left toolbar of the notebook)\n",
    "    - write ``%conda install nom_du_package --yes`` in the new cell\n",
    "    - run the new cell (\"Shift+Enter\" or click \"Run\" and \"Run Selected Cell\" in the menu bar)\n",
    "    - restart the kernel of the Jupyter notebook: click on \"Kernel\" and \"Restart Kernel...\"\n",
    "    - re-run the import cell\n",
    "<div style=\"margin-bottom:10px;\"></div>\n",
    "\n",
    "2. Install within a terminal: \n",
    "    - open a new terminal\n",
    "    - enter the virtual environment you are working in (from where you installed Jupyter notebook) with ``conda activate my_virtual_environment``\n",
    "    - run: ``conda install -k my_package``\n",
    "    - restart the kernel of the Jupyter notebook: click on \"Kernel\" and \"Restart Kernel...\"\n",
    "    - re-run the import cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5411d73d-c71c-433d-81d2-169e69bd00ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Packages and functions successfully imported!\n"
     ]
    }
   ],
   "source": [
    "# Import cell\n",
    "try:\n",
    "    import os\n",
    "    import re\n",
    "    import chardet\n",
    "    import warnings\n",
    "    import traceback\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    import ipywidgets as widgets\n",
    "    from ipyfilechooser import FileChooser\n",
    "    from IPython.display import display, HTML, clear_output\n",
    "except ImportError as e:\n",
    "    print(\"⚠️ Error: \", e)\n",
    "else:\n",
    "    print(\"✅ Packages and functions successfully imported!\")\n",
    "\n",
    "# custom function to detect automatically and return the encoding of edf file\n",
    "def detect_encoding(byte_string, min_confidence=0.6):\n",
    "    result = chardet.detect(byte_string)\n",
    "    encoding = result['encoding']\n",
    "    confidence = result['confidence']\n",
    "    if encoding is None or confidence < min_confidence:\n",
    "        raise UnicodeDecodeError(\"chardet\", byte_string, 0, len(byte_string),\n",
    "                                 f\"\\tUnable to reliably detect encoding. Detected: {encoding} with confidence {confidence}\")\n",
    "    return encoding\n",
    "\n",
    "# custom function to read information from EDF headers, without using the pyedflib package (that was too strict for ICEBERG)\n",
    "# EDF file should follow a strict format, dedicating a specific number of octets for each type of information.\n",
    "# it means that we can read the info octet by octet by specifying the number of octets we expect for the next variable (that is known from the EDF norm)\n",
    "def read_edf_header_custom(file_path):\n",
    "    with open(file_path, 'rb') as f: # open the file in binary mode, to read octet by octet. \n",
    "        header = {}\n",
    "        # detect encoding\n",
    "        raw_header = f.read(256)\n",
    "        encoding = detect_encoding(raw_header)\n",
    "        # print(f\"\\tDetected encoding for {file_path} : {encoding}\")\n",
    "        # Rewind to the beginning of the file\n",
    "        f.seek(0)\n",
    "        \n",
    "        # the first 256 octets are global subject info\n",
    "        header['version'] = f.read(8).decode(encoding).strip()\n",
    "        header['patient_id'] = f.read(80).decode(encoding).strip()\n",
    "        header['recording_id'] = f.read(80).decode(encoding).strip()\n",
    "        header['start_date'] = f.read(8).decode(encoding).strip()\n",
    "        header['start_time'] = f.read(8).decode(encoding).strip()\n",
    "        header['header_bytes'] = int(f.read(8).decode(encoding).strip())\n",
    "        header['reserved'] = f.read(44).decode(encoding).strip()\n",
    "        header['n_data_records'] = int(f.read(8).decode(encoding).strip())\n",
    "        header['duration_data_record'] = float(f.read(8).decode(encoding).strip())\n",
    "        header['n_channels'] = int(f.read(4).decode(encoding).strip())\n",
    "        \n",
    "        # get info per channel\n",
    "        n = header['n_channels']\n",
    "        channel_fields = {\n",
    "            'channel': [],\n",
    "            'transducer_type': [],\n",
    "            'dimension': [],\n",
    "            'physical_min': [],\n",
    "            'physical_max': [],\n",
    "            'digital_min': [],\n",
    "            'digital_max': [],\n",
    "            'prefiltering': [],\n",
    "            'sampling_frequency': [],\n",
    "            'reserved': [],\n",
    "        }\n",
    "\n",
    "        for key in channel_fields:\n",
    "            length = {\n",
    "                'channel': 16,\n",
    "                'transducer_type': 80,\n",
    "                'dimension': 8,\n",
    "                'physical_min': 8,\n",
    "                'physical_max': 8,\n",
    "                'digital_min': 8,\n",
    "                'digital_max': 8,\n",
    "                'prefiltering': 80,\n",
    "                'sampling_frequency': 8,\n",
    "                'reserved': 32,\n",
    "            }[key]\n",
    "            channel_fields[key] = [f.read(length).decode(encoding).strip() for _ in range(n)]\n",
    "\n",
    "        header.update(channel_fields)\n",
    "    \n",
    "    return header\n",
    "\n",
    "# function to extract filter information from the string in headers\n",
    "def extract_filter_value(s, tag):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    match = re.search(rf'{tag}[:\\s]*([\\d\\.]+)\\s*', s, re.IGNORECASE)\n",
    "    return float(match.group(1)) if match else None\n",
    "\n",
    "# custom function to get the sampling frequency out of a dataframe (the df needs to have 'subject' and 'channel' as columns)\n",
    "def get_sf(df, subject, channel):\n",
    "    df_sf = df[(df['subject'] == subject) & (df['channel'] == channel)]\n",
    "    if not df_sf.empty:\n",
    "        return df_sf.iloc[0]['sampling_frequency']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# function to create a widget slider to select the configuration to inspect\n",
    "def mk_config_slider(value = 1, min = 1, max = 5):\n",
    "    config_slider = widgets.IntSlider(\n",
    "    value=value,\n",
    "    min=min,\n",
    "    max=max,\n",
    "    step=1,\n",
    "    description='Selected configuration:',\n",
    "    style={'description_width': '150px'},   # increase description width (to adjust based on the description)\n",
    "    layout=widgets.Layout(width='400px'),   # to adjust widget size\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    "    )\n",
    "    return config_slider\n",
    "\n",
    "# function to print the configuration of a dataset parameter\n",
    "def print_config(i, config_dict, param):\n",
    "    # get the key and value from the dictionary\n",
    "    idx = i - 1\n",
    "    # get participant ID\n",
    "    value = list(config_dict.values())  \n",
    "    v = value[idx]  \n",
    "    # get configuration\n",
    "    key = list(config_dict.keys())\n",
    "    k = key[idx]\n",
    "    \n",
    "    # print info\n",
    "    print(f'Selected configuration: # {i}')\n",
    "    print(f'\\t{param}: {k}')\n",
    "    print(f'\\t{len(v)} participants: {v}')\n",
    "\n",
    "# function to create a scrollable box for long output (e.g., cell loading the data) \n",
    "def print_in_scrollable_box(text, height=300, font_size=\"12px\"):\n",
    "    display(HTML(f'<pre style=\"overflow-y:scroll; height:{height}px; border:1px solid black; padding:10px; font-size:{font_size};\">{text}</pre>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c657ea5-74e0-43d6-9ab2-8b6ed4a23340",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px; background-color:black; border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c9a604-7fe3-4a81-9e60-1587f7cb14e1",
   "metadata": {},
   "source": [
    "## 1. Select study folder, extract information, display general information "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a71a42-dc8b-44c1-828d-de3a75b493cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.1 Select the study folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a34884-abce-42a7-b8db-10e500e75d23",
   "metadata": {},
   "source": [
    "The code cell below will open a widget to select the folder containing your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9124017c-7f30-4794-aab6-55a462a5b85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752577b8aed14f4a8ed607c6d815161d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='C:\\Users\\yvan.nedelec\\OneDrive - ICM\\Documents\\RE_yvan\\projects\\Dream-Toolkit\\python\\Check_E…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c11ba146db74d15b9215942fff17888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# call widget to select your data folder \n",
    "chooser = FileChooser(os.getcwd())\n",
    "chooser.title = \"<b>Choose your study folder</b>\"\n",
    "chooser.show_only_dirs = True\n",
    "\n",
    "# Define output widget to redirect the print within the function\n",
    "out = widgets.Output()\n",
    "\n",
    "# custom function to extract the folder path once the folder has been chosen: \n",
    "def on_folder_selected(chooser):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        chooser.folder_path = chooser.selected_path\n",
    "        print(\"📁 Selected Path:\", chooser.folder_path)\n",
    "        \n",
    "        # get the edf file list \n",
    "        chooser.edf_files = [\n",
    "            f for f in Path(chooser.folder_path).rglob('*.edf')\n",
    "            if not f.name.startswith('._') # don't select files starting with ._ (that can be found in mac for example)\n",
    "            ]\n",
    "        if not chooser.edf_files:\n",
    "            print(f\"⚠️ There is no .edf file in your folder\")\n",
    "        else:\n",
    "            print(f\"\\nThere is {len(chooser.edf_files)} .edf files in your folder!\")\n",
    "        \n",
    "        # check the existence and/or create the summary folder that will receive the summary tables and the report\n",
    "        chooser.summary_path = f'{chooser.folder_path}/summary'\n",
    "        if not os.path.exists(chooser.summary_path):\n",
    "            os.makedirs(chooser.summary_path)\n",
    "            print(\"\\nCreated summary folder at: \" + chooser.summary_path)\n",
    "        else:\n",
    "            print(\"\\nSummary folder already exists. \\nPrevious summary tables (if any) will be overwritten at: \\n\" + chooser.summary_path)\n",
    "\n",
    "# callback to run the function only when a folder is selected\n",
    "chooser.register_callback(on_folder_selected)\n",
    "display(chooser, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe7e801-ae24-4fdd-a177-a2cbd95e4595",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.2 Extract infromation from each file parameters from each participant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d35c8-052c-4a93-b727-2ec51c6c0857",
   "metadata": {},
   "source": [
    "The code cell below will loop across the .edf files to extract the information of each subject.\\\n",
    "It returns a table that can easily be manipulated to access specific information in the rest of the notebook.\\\n",
    "If some files failed to load, their names will be saved in a .tsv file in the summary folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acb6870b-badd-4225-aaef-fc974516dee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No table containing participants information (labelled 'participants.tsv') was found\n",
      "If you have a table, please rename it 'participants.tsv' (and make sure you have columns labelled 'participant_id' and 'group' if any)\n",
      "In the meantime, we will infer participant's group from subfolder organization or filename component\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bead0ffb64924c698128da46addf0f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get variables from the chooser widget\n",
    "folder_path = chooser.folder_path\n",
    "summary_path = chooser.summary_path\n",
    "edf_files = chooser.edf_files\n",
    "\n",
    "# check if there is a participants.tsv file to get different groups or sessions\n",
    "# if there is not a participants.tsv we will try to infer groups from subfolder organization or filename components (additional part from subject number)\n",
    "# in ICEBERG, subfolders define groups within the data folder\n",
    "# in APOMORPHEE, suffixes define nights (\"session\") \n",
    "table_found = False\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    if 'participants.tsv' in files:\n",
    "        table_found = True        \n",
    "        print(f\"Table containing participants information found at: {os.path.join(root, 'participants.tsv')} \")\n",
    "        subj_table_path = os.path.join(root, 'participants.tsv')\n",
    "\n",
    "found_group = False\n",
    "if table_found:\n",
    "    subj_table = pd.read_csv(subj_table_path, sep = '\\t', dtype={'participant_id': str, 'group': str})\n",
    "    if \"group\" in subj_table.columns:\n",
    "        found_group = True\n",
    "        print(f\"We will extract participant's group from it\")\n",
    "    else:\n",
    "        print(f\"No column 'group' was found in the table\")\n",
    "        print(f\"Group will be inferred from subfolder organization or subfolder component\") \n",
    "    \n",
    "else:\n",
    "    print(f\"No table containing participants information (labelled 'participants.tsv') was found\")\n",
    "    print(f\"If you have a table, please rename it 'participants.tsv' (and make sure you have columns labelled 'participant_id' and 'group' if any)\")\n",
    "    print(f\"In the meantime, we will infer participant's group from subfolder organization or filename component in the next cells\")\n",
    "    subj_table = pd.DataFrame()\n",
    "\n",
    "# Initialize a list of dataframes to store file info, which will be concatenated at the end (this is better for performance)\n",
    "df_list = []\n",
    "# Initialize an empty list for files that could not be read\n",
    "failed_list = []\n",
    "output = \"\"\n",
    "\n",
    "# intialize a dynamic output\n",
    "dynamic_out = widgets.Output()\n",
    "display(dynamic_out)\n",
    "\n",
    "for e, edf_path in enumerate(edf_files):\n",
    "    with dynamic_out:\n",
    "        output += (f'file {e+1}/{len(edf_files)}, currently opening file: {edf_path}\\n')\n",
    "        dynamic_out.clear_output(wait=True)\n",
    "        print_in_scrollable_box(output, font_size = \"12px\")\n",
    "        \n",
    "        # read file with the custom function\n",
    "        try:\n",
    "            edf_header = read_edf_header_custom(edf_path) \n",
    "            \n",
    "            # get subject name (corresponding to file_name)\n",
    "            sub_name = edf_path.stem\n",
    "            \n",
    "            # get subject group (from the parent folder because in the ICEBERG database subfolders were created per patient group)\n",
    "            sub_folder = edf_path.parent.name # get the parent folder of the subject file (path)\n",
    "            \n",
    "            # create df from signal info\n",
    "            df = pd.DataFrame(edf_header)\n",
    "                \n",
    "            # theoretical resolution (edf are 16bit files so the eeg signal can take 2^16 values within the dynamic range)\n",
    "            df['res_theoretical'] = (abs(pd.to_numeric(df['physical_min']))+abs(pd.to_numeric(df['physical_max'])))/pow(2,16)\n",
    "            # turn theoretical resolution to uV if dimension is mV (if no dimension, it is a mess)\n",
    "            df.loc[df['dimension'].str.contains('mv', case=False, na=False), 'res_theoretical'] *= 1000\n",
    "            \n",
    "            # get filtering info in different columns\n",
    "            df['lowpass']   = df['prefiltering'].apply(lambda x: extract_filter_value(x, 'LP'))\n",
    "            df['highpass']  = df['prefiltering'].apply(lambda x: extract_filter_value(x, 'HP'))\n",
    "            df['notch']  = df['prefiltering'].apply(lambda x: extract_filter_value(x, 'NOTCH'))\n",
    "            \n",
    "            # add subject info in the dataframe\n",
    "            df['subject'] = sub_name\n",
    "            df['sub_folder'] = sub_folder\n",
    "            df['group'] = np.nan # initialyze column 'group' with NaN\n",
    "            # get group from participants table if any (else group will be inferred from subfolder or filename extension later)\n",
    "            if found_group:\n",
    "                df['group'] = subj_table.loc[subj_table['participant_id'] == sub_name, 'group'].iloc[0]\n",
    "\n",
    "            # extract filename component before and after subject number (so we assume subject name contains at least incrementing numbers that are at the beginning of the file name)  \n",
    "            #   ^       → start of string  \n",
    "            # (.*?)     → group 1: as few chars as possible, up to the first digit  \n",
    "            # (\\d+)     → group 2: the number itself  \n",
    "            # (.*)      → group 3: the rest of the string  \n",
    "            # $         → end of string\n",
    "            pattern = re.compile(r'^(.*?)(\\d+)(.*)$')\n",
    "            m = pattern.match(sub_name)\n",
    "            if m:\n",
    "                pre_comp = m.group(1) or np.nan\n",
    "                sub_num = m.group(2) or np.nan\n",
    "                post_comp = m.group(3) or np.nan\n",
    "            df['pre_fn_comp'] = pre_comp\n",
    "            df['post_fn_comp'] = post_comp\n",
    "            df['sub_num'] = sub_num\n",
    "            \n",
    "            df['path'] = str(edf_path)\n",
    "            df['session'] = np.nan # session will be inferred later from file name component\n",
    "            \n",
    "            # select only the columns of interest\n",
    "            df = df[['subject', 'group', 'session', 'path', 'sub_folder', 'sub_num', 'pre_fn_comp', 'post_fn_comp', 'channel', 'transducer_type', 'dimension', 'sampling_frequency', \n",
    "                 'highpass', 'lowpass', 'notch', 'physical_min', 'physical_max', 'res_theoretical']]\n",
    "            \n",
    "            # store subject data\n",
    "            df_list.append(df)\n",
    "    \n",
    "        except UnicodeDecodeError as e:\n",
    "            err = f\"⚠️ Encoding problem for {edf_path}\\n\"\n",
    "            output += err\n",
    "            clear_output(wait=True)\n",
    "            print_in_scrollable_box(output, font_size=\"12px\")\n",
    "            failed_list.append((edf_path, 'encoding'))\n",
    "        except Exception as e:\n",
    "            # tb = traceback.format_exc()\n",
    "            err = f\"❌ Unexpected problem for {edf_path} : {e}\\n\"\n",
    "            output += err\n",
    "            clear_output(wait=True)\n",
    "            print_in_scrollable_box(output, font_size=\"12px\")\n",
    "            failed_list.append((edf_path, 'other'))\n",
    "   \n",
    "# concatenate dataframe into one and only\n",
    "with warnings.catch_warnings(): # this is to skip a warning not affecting our operation\n",
    "    warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "    df_full = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# save the failed list if not empty:\n",
    "failed_df = pd.DataFrame(failed_list)\n",
    "if not failed_df.empty:\n",
    "    failed_df.to_csv(f'{summary_path}/failed_edf_read.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving the list of files that could not be read to: \\n{summary_path}/failed_edf_read.tsv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe23577-f4c7-4616-944c-322ac7d83552",
   "metadata": {},
   "source": [
    "### 1.3 Dataset general information (# participants, groups, recorded sensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1ebf47-0b76-402e-8282-5f7cfbb16eb6",
   "metadata": {},
   "source": [
    "In the code cell below, we extract group and session information, and we save the summary table (in the summary folder) so that it can be visually inspected with Excel, or reloaded in other script if needed.\\\n",
    "\\\n",
    "To extract group infromation:\n",
    "- we check if group was read from participants.tsv\n",
    "- else we try to infer it from subfolders (e.g. ICEBERG databaase organization)\n",
    "- else we try to infer it from filename component (characters before or after the participant number in the filename)  \n",
    "- else we consider there is only one group in the study\n",
    "\n",
    "To extract session information: \n",
    "- we infer it from filename components (if there is more than one filename component per participant)\n",
    "- else we consider there is only one session per participant\n",
    "\n",
    "Then, we display the general information of the dataset (# files, # participants, # groups, # sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c84fc79b-d7c5-4c63-bd43-aba23e4ab332",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get group information:\n",
      "The column 'group' is empty, we will infer group from subfolder, if any...\n",
      "There is no distinct folders for groups.\n",
      "Trying to infer group from filename component...\n",
      "Did not succed to identify group from filename component.\n",
      "It seems that there is only one group in the study!\n",
      "\n",
      "Get session information\n",
      ">>> Session inferred from filename component (after subject number) <<<\n",
      "\n",
      "Saving full informations from the dataset to:\n",
      "C:\\Users\\yvan.nedelec\\OneDrive - ICM\\Documents\\RE_yvan\\projects\\noemie_rescue\\data/summary/FULL_summary_table_edf.tsv\n",
      "\n",
      "\n",
      "Dataset information:\n",
      "- Number of files: 66\n",
      "- Number of participants: 33\n",
      "- Number of groups: 1\n",
      "- Number of sessions: 2\n"
     ]
    }
   ],
   "source": [
    "# get group information, from participants.tsv file, sub_folder, or filename component\n",
    "print(\"Get group information:\")\n",
    "if df_full['group'].isna().all():\n",
    "    print(\"The column 'group' is empty, we will infer group from subfolder, if any...\")\n",
    "    if len(df_full['sub_folder'].unique()) > 1:\n",
    "        df_full['group'] = df_full['sub_folder']\n",
    "        print(\">>> Group inferred from folders within the database <<<\")\n",
    "    else:\n",
    "        print(\"There is no distinct folders for groups.\")\n",
    "        print(\"Trying to infer group from filename component...\")\n",
    "        # looping across subject number (and not subject filename) to test if there are multiple filename components per subject (to disentangle groups from session)  \n",
    "        count_precomp = np.zeros(len(df_full['sub_num'].unique()))\n",
    "        count_postcomp = np.zeros(len(df_full['sub_num'].unique()))\n",
    "        for sn, sub_num in enumerate(df_full['sub_num'].unique()):\n",
    "            df_sub = df_full[df_full['sub_num'] == sub_num]\n",
    "            count_precomp[sn] = len(df_sub['pre_fn_comp'].unique())\n",
    "            count_postcomp[sn] = len(df_sub['post_fn_comp'].unique())\n",
    "        # fn component is a group if within subject there is only one component, but there are multiple components between subject\n",
    "        # 1st, try for component before the subject number, 2nd try for component after the subject number \n",
    "        if len(df_full['pre_fn_comp'].unique()) > 1 and count_precomp.mean() == 1:\n",
    "            df_full['group'] = df_full['pre_fn_comp']\n",
    "            print(\">>> Group inferred from filename component (before subject number) <<<\")\n",
    "        elif len(df_full['post_fn_comp'].unique()) > 1 and count_postcomp.mean() == 1:\n",
    "            df_full['group'] = df_full['post_fn_comp']\n",
    "            print(\">>> Group inferred from filename component (after subject number) <<<\")\n",
    "        else:\n",
    "            print(\"Did not succed to identify group from filename component.\")\n",
    "            print(\"It seems that there is only one group in the study!\")\n",
    "else:\n",
    "    print(\">>> Group information coming from participants.tsv <<<\")\n",
    "\n",
    "print(\"\\nGet session information\")\n",
    "if len(df_full['pre_fn_comp'].unique()) > 1 and count_precomp.mean() > 1:\n",
    "    print(\">>> Session inferred from filename component (before subject number) <<<\")\n",
    "    df_full['session'] = df_full['pre_fn_comp']\n",
    "elif len(df_full['post_fn_comp'].unique()) > 1 and count_postcomp.mean() > 1:\n",
    "    print(\">>> Session inferred from filename component (after subject number) <<<\")\n",
    "    df_full['session'] = df_full['post_fn_comp']\n",
    "else:\n",
    "    print(\"It seems that there is only one session in the study\")\n",
    "\n",
    "# save summary table containing full info\n",
    "df_full.to_csv(f'{summary_path}/FULL_summary_table_edf.tsv', sep = '\\t')\n",
    "print(f'\\nSaving full informations from the dataset to:\\n{summary_path}/FULL_summary_table_edf.tsv')\n",
    "\n",
    "print(\"\\n\\nDataset information:\")\n",
    "print(f\"- Number of files: {len(df_full['subject'].unique())}\")\n",
    "print(f\"- Number of participants: {len(df_full['sub_num'].unique())}\")\n",
    "print(f\"- Number of groups: {len(df_full['group'].unique())}\")\n",
    "print(f\"- Number of sessions: {len(df_full['session'].unique())}\")\n",
    "\n",
    "if len(df_full['group'].unique()) > 1:\n",
    "    print(\"\\nParticipants per groups:\")\n",
    "    print(df_full.drop_duplicates().groupby('group').agg(n_subjects=('subject', 'nunique')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1131160-d67d-48bc-8122-15fcb19a24fc",
   "metadata": {},
   "source": [
    "In the code cell below, we print the unique values of the sensors whithin your database, in case you want to make sure that one specific type of sensors is in your dataset. \\\n",
    "For the rest of the notebook, we will focus, separately, on EEG, EOG and ECG sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdf3b8b8-fdc9-4b34-abef-5cbaab4a1f6f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full recorded sensors configuration of your database (across participants): \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-y:scroll; height:150px; border:1px solid black; padding:10px; font-size:12px;\">Fp1\n",
       "C3\n",
       "O1\n",
       "A2\n",
       "EOG G\n",
       "EOG D\n",
       "EMG 1\n",
       "EMG 2\n",
       "EMG JD\n",
       "EMG JG\n",
       "ECG\n",
       "Mic\n",
       "Flux\n",
       "Thermistance\n",
       "Thoracic\n",
       "Abdominal\n",
       "Sum\n",
       "Pulse\n",
       "SpO2\n",
       "Pleth\n",
       "Position\n",
       "EDF Annotations\n",
       "E1-M2\n",
       "E2-M2\n",
       "F4-M1\n",
       "C4-M1\n",
       "C3-M2\n",
       "O2-M1\n",
       "EMG_L\n",
       "Ronfl\n",
       "Thor\n",
       "Abdo\n",
       "FC\n",
       "Pl?th\n",
       "Pos\n",
       "Jambe_R\n",
       "Jambe_L\n",
       "Therm\n",
       "F4\n",
       "C4\n",
       "O2\n",
       "M1\n",
       "M2\n",
       "Chin1\n",
       "Chin2\n",
       "ECG1\n",
       "ECG2\n",
       "F3-M2\n",
       "O1-M2\n",
       "EMG_R\n",
       "E1\n",
       "E2\n",
       "F3\n",
       "Chin3\n",
       "LLeg1-LLeg2\n",
       "RLeg1-RLeg2\n",
       "EEG F2\n",
       "EEG C4\n",
       "EEG O2\n",
       "EEG T4\n",
       "EEG F1\n",
       "EEG C3\n",
       "EEG O1\n",
       "EEG T3\n",
       "EEG A2\n",
       "MO-D\n",
       "MO-G\n",
       "MENTON\n",
       "JAM-Dt\n",
       "JAM-Ga\n",
       "SAT\n",
       "ABD\n",
       "THO\n",
       "RONF\n",
       "PRES\n",
       "THERM\n",
       "PTT\n",
       "Pouls\n",
       "FCbb\n",
       "POS</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('\\nFull recorded sensors configuration of your database (across participants): ')\n",
    "ch_output = '\\n'.join(df_full['channel'].unique())\n",
    "print_in_scrollable_box(ch_output, height = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d188389-063d-43bc-a8c5-b6dfe93d5de8",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px; background-color:black; border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4bf662-62bb-4046-a98b-8298c117276f",
   "metadata": {},
   "source": [
    "## 2. Inspect EEG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020e2fd-b7ec-4249-a53a-f010f38ffcc9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.1 Select only the EEGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c434167-29d3-4fd0-894e-8438c8ff5d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving informations from EEG channels to:\n",
      "C:\\Users\\yvan.nedelec\\OneDrive - ICM\\Documents\\RE_yvan\\projects\\ICEBERG\\PSG/summary/EEG_summary_table.tsv\n"
     ]
    }
   ],
   "source": [
    "# select only EEG channels and return a warning if the number of participant is smaller/higher\n",
    "mask_ch = df_full['transducer_type'].str.contains(r'EEG|AGAGCL ELECTRODE', case = False, na=False) # create a mask that returns true for lines containing either EEG/AGAGCL ELECTRODE in the transducer_type column\n",
    "df_ch = df_full[mask_ch]\n",
    "# remove the emg channels that were captured with the AGAGCL ELECTRODE transducer type \n",
    "df_ch = df_ch[~df_ch['channel'].str.contains(r'emg|ecg|eog', case=False, na=False)] # the ~ allows to not select the selection (like ! in matlab)\n",
    "\n",
    "# Check if the number of participants with only EEG is the same as df_full. \n",
    "# If not, it might be because the transducer type was no correctly detected. \n",
    "# One possibility is to add the type of transducer to the condition line 2 of this cell.\n",
    "if len(df_full['subject'].unique()) > len(df_ch['subject'].unique()):\n",
    "    # identify missing subjects\n",
    "    missing_sub = set(df_full['subject'].unique()) - set(df_ch['subject'].unique())\n",
    "    print('\\n!!! There is less participants in the dataset with only EEGs !!!')\n",
    "    print(f'Missing participants: {missing_sub}')\n",
    "    print(\"\\nEither these participants don't have EEGs.\")\n",
    "    print(\"Or the transducer type was not correctly detected.\")\n",
    "    # get df of missing sub to save and inspect\n",
    "    df_miss = df_full[df_full['subject'].isin(missing_sub)]\n",
    "    df_miss.to_csv(f'{summary_path}/EEG_missing_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from missing participants to:\\n{summary_path}/EEG_missing_edf.tsv')\n",
    "    print('Please inspect the file, and specifically the column transducer_type')\n",
    "elif len(df_full['subject'].unique()) < len(df_ch['subject'].unique()):\n",
    "    print('\\n!!! There is more participants in the dataset with only EEGs !!!')\n",
    "    print('This should not be the case.')\n",
    "    print('Please inspect what is happening in a code editor (spyder..), or ask Yvan.')\n",
    "    more_sub = set(df_ch['subject'].unique()) - set(df_full['subject'].unique())\n",
    "    df_more = df_ch[df_ch['subject'].isin(more_sub)]\n",
    "    df_more.to_csv(f'{summary_path}/EEG_suspect_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from suspect participants to:\\n{summary_path}/EEG_suspect_edf.tsv')\n",
    "\n",
    "# saving info from eeg\n",
    "df_ch.to_csv(f'{summary_path}/EEG_summary_table.tsv', sep = '\\t')\n",
    "print(f'\\nSaving informations from EEGs to:\\n{summary_path}/EEG_summary_table.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a752f46-632f-4120-b905-f32a26a4d6cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.2 Inspect EEG configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7373270-1a31-4919-baf8-349c0fa408b5",
   "metadata": {},
   "source": [
    "There will be likely many EEG configurations (especially with multicentric dataset).  \\\n",
    "\\\n",
    "For polysomnographic EEG, there should be at least:\n",
    "- 4 EEG (Fp1, C3, O1 and A2 that will be used as the reference) (or less frequently Fp2, C4, O2 and A1)\n",
    "\n",
    "Depending on the analysis you plan, if one configuration does not contain those electrodes you will need either to re-export the data or to exclude the participant. \\\n",
    "\\\n",
    "If the EEG label is Fp1-A2, it means that your data is already re-referenced to A2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "994eb7b0-4742-4d3c-94f0-36b34b2b065b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> There is multiple EEG configurations in your dataset! <<<\n",
      "\n",
      "\tNumber of different channels configuration: 11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the EEG configuration per participant \n",
    "ch_per_sub = df_ch.groupby('subject')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "\n",
    "# identify the channel configuration of each participant and store them in a dict to print per channel config\n",
    "ch_config_dict = {}\n",
    "for config in ch_per_sub.unique():\n",
    "    sub = ch_per_sub[ch_per_sub == config].index.tolist()\n",
    "    ch_config_dict[config] = sub\n",
    "\n",
    "if len(ch_config_dict) > 1:\n",
    "    print('\\n>>> There is multiple EEG configurations in your dataset! <<<')    \n",
    "    print(f'\\n\\tNumber of different configuration: {len(ch_config_dict)}\\n')\n",
    "else:\n",
    "    print('\\n>>> There is only one EEG configuration in your dataset! <<<')\n",
    "\n",
    "# # print info per channel configuaration\n",
    "# for i, (config, participants) in enumerate(ch_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Channels ({len(config)}) : {config}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c6905-ebf9-4b4d-ae5e-6b210dcc4546",
   "metadata": {},
   "source": [
    "To inspect the participants ID in one configuration, run the cell just below after changing the parameter  \"configuration_to_inspect\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "233e9c0b-321f-420d-8161-53561474be52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ac822594a44cde83a6ca13fe0a0695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='Selected configuration:', layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget to select the configuration of interest\n",
    "config_ch_slider = mk_config_slider(value = 1, min = 1, max = len(ch_config_dict))\n",
    "\n",
    "# print the configuration selected\n",
    "# interact with the slider output through the printing function \n",
    "widgets.interact(lambda i: print_config(i, config_dict=ch_config_dict, param=\"Channels\"), i=config_ch_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a7e4c3-6e5a-4b05-98e3-2183bf7b0e25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.3 Inspect EEG sampling frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f44f5-bc03-46f7-ae35-401ec0e3ab12",
   "metadata": {},
   "source": [
    "Ideally, you expect to have only one sampling frequency for all the EEGs and participants. \\\n",
    "In practice, you might have different sampling frequencies across participants (especially with multicentric dataset).\\\n",
    "\\\n",
    "Each EEG analysis software handles multiple sampling frequencies (that can happen for EEG and EOG) within participants differently. For example:\n",
    "- MNE python will automatically upsample channels to the highest sampling frequency\n",
    "- Fieldtrip will load only a subset of channels (with the sampling frequency the most represented)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87a23e13-8c7f-4cb1-af1d-a97a5b828e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> There is multiple sampling frequency for EEGs in your dataset! <<<\n",
      "\n",
      "\tNumber of different sampling frequency configuration: 2\n",
      "\n",
      "Quick overlook of the EEGs associated to sampling frequencies:\n",
      "\n",
      "256 Hz: ['Fp1' 'Fp2' 'F3' 'T7/T3' 'C3' 'Cz' 'C4' 'T8/T4' 'A1' 'A2' 'O1' 'O2' 'F7'\n",
      " 'F4' 'P7/T5' 'P3' 'P4' 'P8/T6' 'Pz' 'Fp1-A2' 'C3-A2' 'O1-A2' 'T3' 'T4']\n",
      "\n",
      "400 Hz: ['FP1-A2' 'C3-A2' 'O1-A2' 'FP2-A1' 'C4-A1' 'O2-A1' 'T3-A2' 'T4-A1']\n"
     ]
    }
   ],
   "source": [
    "# the sampling frequency configuration\n",
    "sf_per_sub = df_ch.groupby('subject')['sampling_frequency'].apply(lambda x: tuple(sorted(set(x))))\n",
    "# identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "sf_config_dict = {}\n",
    "for config in sf_per_sub.unique():\n",
    "    sub = sf_per_sub[sf_per_sub == config].index.tolist()\n",
    "    sf_config_dict[config] = sub\n",
    "\n",
    "# print info per sf configuration (maybe print it only for multiple config)\n",
    "if len(sf_config_dict) > 1:\n",
    "    print('\\n>>> There is multiple sampling frequency for EEGs in your dataset! <<<')    \n",
    "    print(f'\\n\\tNumber of different sampling frequency configuration: {len(sf_config_dict)}\\n')\n",
    "    print('Quick overlook of the EEGs associated to sampling frequencies:')\n",
    "    for s, sf in enumerate(df_ch['sampling_frequency'].unique()):\n",
    "        # select only rows with the current sf\n",
    "        df_sf = df_ch[df_ch['sampling_frequency'] == sf].copy()\n",
    "        print(f'\\n{sf} Hz: {df_sf[\"channel\"].unique()}')\n",
    "else:\n",
    "    print(f'\\n>>> There is only one sampling frequency for EEGs in your dataset: {df_ch['sampling_frequency'].unique()} <<<')\n",
    "\n",
    "# print('\\nSampling frequency configurations:\\n')\n",
    "# for i, (config, participants) in enumerate(sf_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Sampling frequency ({len(config)}) : {config}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49730cce-9c23-48da-afbd-2d63f0774c94",
   "metadata": {},
   "source": [
    "To inspect the participants ID in one configuration, run the cell just below after changing the parameter  \"configuration_to_inspect\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2cdcf25-4bc4-44db-abf9-b697c963f721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3488b6a70d354e33a99ff2fb0fd10093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='Selected configuration:', layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget to select the configuration of interest\n",
    "config_sf_slider = mk_config_slider(value = 1, min = 1, max = len(sf_config_dict))\n",
    "\n",
    "# print the configuration selected\n",
    "# interact with the slider output through the printing function \n",
    "widgets.interact(lambda i: print_config(i, config_dict=sf_config_dict, param=\"Sampling frequencies\"), i=config_sf_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e85239-2e34-429c-9ddd-192e2dab65a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.4 Inspect EEG filtering parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08319a27-d470-44c1-b589-875cb7512049",
   "metadata": {},
   "source": [
    "Ideally with EEG sleep data, you want no lowpass nor notch filter, and a very low highpass filter around 0.05 Hz (to remove slow drift in long recordings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b553a505-1807-4ecf-bf4e-71b6b8782387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Filtering parameters are not fully consistent in EEGs across the dataset! <<<\n",
      "\n",
      "\tNumber of different EEG filters configurations: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if len(df_ch['highpass'].unique())+len(df_ch['lowpass'].unique())+len(df_ch['notch'].unique()) == 3:\n",
    "    print('\\n>>> All EEGs have the same filtering parameters! <<<')\n",
    "elif len(df_ch['highpass'].unique())+len(df_ch['lowpass'].unique())+len(df_ch['notch'].unique()) > 3:\n",
    "    print('\\n>>> Filtering parameters are not fully consistent in EEGs across the dataset! <<<')\n",
    "else:\n",
    "    print('\\n>>> There may have been a problem in reading the filtering parameters. Here is the output: <<<')\n",
    "\n",
    "# Get the list of participants with different filtering parameters\n",
    "# 1st replace NaN because groupby does not like NaN\n",
    "df_filt = df_ch.copy()\n",
    "df_filt[['lowpass', 'highpass', 'notch']] = df_filt[['lowpass', 'highpass', 'notch']].fillna('missing')\n",
    "\n",
    "config_filters = (\n",
    "    df_filt.groupby(['lowpass', 'highpass', 'notch'])['subject']\n",
    "    .apply(lambda x: sorted(set(x)))\n",
    "    .reset_index(name = 'subjects')\n",
    ")\n",
    "\n",
    "# print filter configuration\n",
    "print(f'\\n\\tNumber of different EEG filters configurations: {len(config_filters)}\\n')\n",
    "# print('\\nFilters configurations: ')\n",
    "# r=1\n",
    "# for row in config_filters.itertuples(index=False):\n",
    "#     print(f'Configuration #{r} ({len(row.subjects)} participants)')\n",
    "#     print(f'highpass: {row.highpass}, lowpass: {row.lowpass}, notch: {row.notch}\\n')\n",
    "#     r=r+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ded87ff-dd63-409a-b15c-a253213e9784",
   "metadata": {},
   "source": [
    "To inspect the participants ID in one configuration, run the cell just below after changing the parameter  \"configuration_to_inspect\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f080cb-0bf0-45ce-ac69-f72f8fe4edc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da43ce822d8b48e9bfa941c696dee77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='Selected configuration:', layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget to select the configuration of interest\n",
    "config_filter_slider = mk_config_slider(value = 1, min = 1, max = len(config_filters))\n",
    "\n",
    "# function to rpint filters configurations\n",
    "def print_filters(config_slider):\n",
    "    # get the info from the dataframe\n",
    "    idx = config_slider - 1\n",
    "    sID = config_filters.iloc[idx]['subjects']\n",
    "    hpass = config_filters.iloc[idx]['highpass']\n",
    "    lpass = config_filters.iloc[idx]['lowpass']\n",
    "    notch = config_filters.iloc[idx]['notch']\n",
    "    \n",
    "    # print info\n",
    "    print(f'Selected configuration: # {config_slider}')\n",
    "    print(f'\\tFilters configuration: highpass: {hpass}; lowpass: {lpass}; notch: {notch}')\n",
    "    print(f'\\t{len(sID)} participants: {sID}')\n",
    "\n",
    "widgets.interact(print_filters, config_slider = config_filter_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c8623-a3a3-4ebe-a94f-73faf82e6a7a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.5 Inspect EEG units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed44982-de48-4222-a2e3-0ef7b323bae6",
   "metadata": {},
   "source": [
    "At the exportation, channels can be imported in different units. \\\n",
    "Each analysis software will handle units differently, so it can be helpful to know which units your dataset contains. \n",
    "- MNE python will automatically detect the units and convert the data to Volt. However, if the unit is not read correctly, the data will **not** be converted (e.g. \"UV\" is not interpredted as uV, therefore data are not converted to Volt )\n",
    "- fieldtrip is loading the data with their unit of origin, so you might want to convert all channels to the same unit before your analysis  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2ffc618-1e2d-48de-be65-d0f81c87be3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Multiple units were found! <<<\n",
      "\n",
      "\tNumber of different units configurations: 2\n",
      "\n",
      "Quick overlook of channels associated to units:\n",
      "\n",
      "uV: ['Fp1' 'Fp2' 'F3' 'T7/T3' 'C3' 'Cz' 'C4' 'T8/T4' 'A1' 'A2' 'O1' 'O2' 'F7'\n",
      " 'F4' 'P7/T5' 'P3' 'P4' 'P8/T6' 'Pz' 'Fp1-A2' 'C3-A2' 'O1-A2' 'T3' 'T4']\n",
      "\n",
      "UV: ['FP1-A2' 'C3-A2' 'O1-A2' 'FP2-A1' 'C4-A1' 'O2-A1' 'T3-A2' 'T4-A1']\n"
     ]
    }
   ],
   "source": [
    "if len(df_ch['dimension'].unique()) == 1:\n",
    "    print(f'\\n>>> All EEGs have the same unit: {df_ch[\"dimension\"].unique()} <<<\\n')\n",
    "elif len(df_ch['dimension'].unique()) > 1:\n",
    "    print('\\n>>> Multiple units were found! <<<')\n",
    "    print(f'\\n\\tNumber of different units configurations: {len(df_ch['dimension'].unique())}\\n')\n",
    "    print('Quick overlook of EEGs associated to units:')\n",
    "    for u, unit in enumerate(df_ch['dimension'].unique()):\n",
    "        # select only rows with the current sf\n",
    "        df_unit = df_ch[df_ch['dimension'] == unit].copy()\n",
    "        print(f'\\n{unit}: {df_unit[\"channel\"].unique()}')\n",
    "    \n",
    "\n",
    "# print the different configuration of units \n",
    "# if info about sf configuration is needed\n",
    "unit_per_sub = df_ch.groupby('subject')['dimension'].apply(lambda x: tuple(sorted(set(x))))\n",
    "ch_per_unit = df_ch.groupby('dimension')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "# identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "unit_config_dict = {}\n",
    "for config in unit_per_sub.unique():\n",
    "    sub = unit_per_sub[unit_per_sub == config].index.tolist()\n",
    "    unit_config_dict[config] = sub\n",
    "\n",
    "# print info per sf configuration\n",
    "# print('\\nUnits configurations:')\n",
    "# for i, (config, participants) in enumerate(unit_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Unit ({len(config)}) : {config}\\n')\n",
    "#     # print(f\"Participants : {participants}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a472b7c-c413-485b-8c62-73bcf20d2c00",
   "metadata": {},
   "source": [
    "To inspect the participants ID in one configuration, run the cell just below after changing the parameter  \"configuration_to_inspect\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b79f538-1c2b-45f8-8b0f-06874c4352f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d264fdbc66754fb7999fba56e3c6faa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='Selected configuration:', layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget to select the configuration of interest\n",
    "config_unit_slider = mk_config_slider(value = 1, min = 1, max = len(unit_config_dict))\n",
    "\n",
    "# print the configuration selected\n",
    "# interact with the slider output through the printing function \n",
    "widgets.interact(lambda i: print_config(i, config_dict=unit_config_dict, param=\"Units\"), i=config_unit_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01871a8-6bca-4642-8262-66c5737d43cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.6 Inspect EEG signal inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1761b1c6-ac72-4c39-a8b6-f385dba0f0f9",
   "metadata": {},
   "source": [
    "Some softwares (e.g. profusion from compumedics) allows to invert the polarity of the exported data. It can be extremely confusing and can lead to wrong results. \\\n",
    "Here, we inspect if the signal is inverted by checking if the minimum physical boundary is higher than the maximum physical boundary. \\\n",
    "For .edf file, the physical boundaries are values that are set when exporting the data by specifying the scale of the data. \\\n",
    "\\\n",
    "In profusion (from compumedics) a scale of 1mV will lead to a min physical boundary of -500 uV and a max physical boundary of +500 uV.\\\n",
    "\\\n",
    "For other EEG format and software, the dynamical range might be set before recording (e.g. to be specified in the montage) and can't be changed at the exportation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1661b24f-eb0c-4787-ad96-538004d08ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> No inverted polarity was detected in EEGs <<<\n",
      "\n",
      "Saving informations from EEG inverted polarity channels to:\n",
      "C:\\Users\\yvan.nedelec\\OneDrive - ICM\\Documents\\RE_yvan\\projects\\ICEBERG\\PSG/summary/EEG_inverted_polarity_edf.tsv \n",
      "(will be empty if no inverted polarity)\n"
     ]
    }
   ],
   "source": [
    "# select rows where the physical min is greater than the physical max\n",
    "df_inv = df_ch[df_ch['physical_min'] > df_ch['physical_max']]\n",
    "\n",
    "if not df_inv.empty:\n",
    "    print('\\n>>> Inverted polarity detected in EEGs! <<<')\n",
    "    print(f'{df_inv.shape[0]} EEGs have an inverted polarity (from {df_ch.shape[0]} EEGs in {len(edf_files)} edf files)')\n",
    "    print(df_inv[['subject', 'channel', 'dimension', 'physical_min', 'physical_max']])\n",
    "else:\n",
    "    print('\\n>>> No inverted polarity was detected in EEGs <<<')\n",
    "df_inv.to_csv(f'{summary_path}/EEG_inverted_polarity_edf.tsv', sep = '\\t')\n",
    "print(f'\\nSaving informations from inverted polarity EEGs to:\\n{summary_path}/EEG_inverted_polarity_edf.tsv \\n(will be empty if no inverted polarity)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba40bd84-ccc9-4f33-b7a5-9cdf69c49860",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.7 Inspect EEG theoretical resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc718a-33cd-45db-a431-39905dd59c3f",
   "metadata": {},
   "source": [
    "The theoretical resolution of .edf file is the minimum amplitude variation that can be recorded between two samples. \\\n",
    "Since .edf file is a 16-bit compressed format (meaning that a datapoint can take 2^16 value between a min and a max), we computed the theoretical resolution by dividing the dynamical range (upper/lower physical boundaries)  by 2^16. \\\n",
    "Ideally, resolution should be around 0.01 uV (or lower). \\\n",
    "\\\n",
    "Hence, to improve the theoretical resolution, we can reduce the min and max values of the dynamic range. However, reducing the dynamic range can lead to loss of data information (because the signal can't get higher or lower than the boundaries), an issue called signal clipping.\\\n",
    "\\\n",
    "Below, we detect EEGs that have a resolution higher than 0.1 uV.\\\n",
    "You can change the resolution threshold with the widget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5555defd-0390-4578-9808-21a28ffc3114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe69366dbdf48a39e9e1175c69069a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedFloatText(value=0.1, description='Resolution threshold (uV):', layout=Layout(widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# res_theo have been converted to uV, but if dimension was not read or not indicated in the headers, it might not work. I might need to add something more robust\n",
    "r_thres = widgets.BoundedFloatText(\n",
    "    value=0.1,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    style={'description_width': '150px'},  # augmente la largeur de la description\n",
    "    layout=widgets.Layout(width='230px'),   # ajuste la taille totale du widget si besoin\n",
    "    description='Resolution threshold (uV):',\n",
    "    disabled=False\n",
    ");\n",
    "\n",
    "# define a function to interact with the widget\n",
    "def check_bad_res(threshold):\n",
    "    r_mask = df_ch['res_theoretical'] >= threshold\n",
    "    bad_res = df_ch[r_mask]\n",
    "    \n",
    "    if not bad_res.empty:\n",
    "        print(f'\\n>>> Poor resolution detected in EEGs! (>= {threshold} uV) <<<')\n",
    "        print(f'{bad_res.shape[0]} EEGs have a very poor resolution (from {df_ch.shape[0]} EEGs in {len(edf_files)} edf files)')\n",
    "        print(bad_res[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "    else:\n",
    "        print(f'\\n>>> No EEG with a poor resolution (>= {threshold} uV) was detected! <<<')\n",
    "    bad_res.to_csv(f'{summary_path}/EEG_bad_resolution_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from bad resolution EEGs to:\\n{summary_path}/EEG_bad_resolution_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "\n",
    "widgets.interact(check_bad_res, threshold=r_thres);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e52b08f-3070-4184-b6ad-5c625401d1ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.8 Inspect EEG dynamic range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f995de14-a19d-44cf-ab2a-53ae0a40e6d5",
   "metadata": {},
   "source": [
    "As mentionned above, a small dynamic range will lead to a good signal resolution, but can lead to signal clipping.\\\n",
    "Signal clipping happens when the signal reach the physical boundaries (min or max) and therefore is blocked at this value. It results in a loss of data information.\\\n",
    "\\\n",
    "Typical physiological EEG data (good quality) varies from +/-200 uV.\\\n",
    "Below, we check if the dynamic range physical boundaries are lower than 400 uV (+/- 200 uV). \\\n",
    "You can change the dynamic range threshold with the widget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6314a71-8c6d-4819-9ea0-0d3db1ee91ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b112bf1da04bb2ac7124e340a9b5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedFloatText(value=400.0, description='Dynamic range threshold (uV):', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dr_thres = widgets.BoundedFloatText(\n",
    "    value=400,\n",
    "    min=0,\n",
    "    max=5000,\n",
    "    step=0.1,\n",
    "    style={'description_width': '200px'},  # augmente la largeur de la description\n",
    "    layout=widgets.Layout(width='270px'),   # ajuste la taille totale du widget si besoin\n",
    "    description='Dynamic range threshold (uV):',\n",
    "    disabled=False\n",
    ");\n",
    "\n",
    "\n",
    "def check_bad_dr(threshold):\n",
    "    dr_mask = df_ch['res_theoretical']*pow(2,16) <= threshold\n",
    "    bad_dr = df_ch[dr_mask]\n",
    "    \n",
    "    if not bad_dr.empty:\n",
    "        print(f'\\n>>> Small dynamic range detected in EEGs! (<= {threshold} uV) <<<\\n')\n",
    "        print(f'{bad_dr.shape[0]} EEGs have a small dynamic range (from {df_ch.shape[0]} EEGs in {len(edf_files)} edf files)')\n",
    "        print(bad_dr[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "    else:\n",
    "        print(f'\\n>>> No EEG with a small dynamic range(<= {threshold} uV) was detected! <<<')\n",
    "    bad_dr.to_csv(f'{summary_path}/EEG_bad_dynamic_range_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from bad dynamic range EEGs to:\\n{summary_path}/EEG_bad_dynamic_range_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "\n",
    "widgets.interact(check_bad_dr, threshold = dr_thres);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3ab2fc-79e6-4c30-8155-ed45ec27ce6a",
   "metadata": {},
   "source": [
    "## 5. Inspect EOG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a154cb-34df-49cd-bc64-6dba5dfa5752",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.1 Select only EOGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5eda13e-1ed6-41e1-b9e7-ffe670ce9ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving informations from EOG channels to:\n",
      "C:\\Users\\yvan.nedelec\\OneDrive - ICM\\Documents\\RE_yvan\\projects\\ICEBERG\\PSG/summary/EOG_summary_table.tsv\n"
     ]
    }
   ],
   "source": [
    "# select only EOGs and return a warning if the number of participant is smaller/higher\n",
    "mask_eog = df_full['channel'].str.contains(r'EOG', case = False, na=False) # create a mask that returns true for lines containing either EOG in the channel column\n",
    "df_eog = df_full[mask_eog]\n",
    "# remove the emg channels that were captured with the AGAGCL ELECTRODE transducer type \n",
    "# df_eog = df_eog[~df_eog['channel'].str.contains(r'emg|ecg|eeg|a1|a2', case=False, na=False)] # the ~ allows to not select the selection (like ! in matlab)\n",
    "\n",
    "# Check if the number of participants with only EOG is the same as df_full. \n",
    "# If not, it might be because the transducer type was no correctly detected. \n",
    "# One possibility is to add the type of transducer to the condition line 2 of this cell.\n",
    "if len(df_full['subject'].unique()) > len(df_eog['subject'].unique()):\n",
    "    # identify missing subjects\n",
    "    missing_sub = set(df_full['subject'].unique()) - set(df_eog['subject'].unique())\n",
    "    print('\\n!!! There is less participants in the dataset with only EOGs !!!')\n",
    "    print(f'Missing participants: {missing_sub}')\n",
    "    print(\"\\nEither these participants don't have EOGs.\")\n",
    "    print(\"Or the transducer type was not correctly detected.\")\n",
    "    # get df of missing sub to save and inspect\n",
    "    df_eogmiss = df_full[df_full['subject'].isin(missing_sub)]\n",
    "    df_eogmiss.to_csv(f'{summary_path}/EOG_missing_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from missing participants to:\\n{summary_path}/EOG_missing_edf.tsv')\n",
    "    print('Please inspect the file, and specifically the column transducer_type')\n",
    "elif len(df_full['subject'].unique()) < len(df_eog['subject'].unique()):\n",
    "    print('\\n!!! There is more participants in the dataset with only EOGs !!!')\n",
    "    print('This should not be the case.')\n",
    "    print('Please inspect what is happening in a code editor (spyder..), or ask Yvan.')\n",
    "    more_sub = set(df_eog['subject'].unique()) - set(df_full['subject'].unique())\n",
    "    df_more = df_eog[df_eog['subject'].isin(more_sub)]\n",
    "    df_more.to_csv(f'{summary_path}/EOG_suspect_edf.csv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from suspect participants to:\\n{summary_path}/EOG_suspect_edf.tsv')\n",
    "\n",
    "# saving info from EOG\n",
    "df_eog.to_csv(f'{summary_path}/EOG_summary_table.tsv', sep = '\\t')\n",
    "print(f'\\nSaving informations from EOGs to:\\n{summary_path}/EOG_summary_table.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea70be-3298-4648-8f5f-0f074252632d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.2 Inspect EOG configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caee87d7-45e7-4a12-a718-9de5c6cf0dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> There is multiple EOG configurations in your dataset! <<<\n",
      "\n",
      "\tNumber of different channels configuration: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the EOG configuration per participant \n",
    "ch_per_sub = df_eog.groupby('subject')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "\n",
    "# identify the EOG configuration of each participant and store them in a dict to print per EOG config\n",
    "ch_config_dict = {}\n",
    "for config in ch_per_sub.unique():\n",
    "    sub = ch_per_sub[ch_per_sub == config].index.tolist()\n",
    "    ch_config_dict[config] = sub\n",
    "\n",
    "if len(ch_config_dict) > 1:\n",
    "    print('\\n>>> There is multiple EOG configurations in your dataset! <<<')    \n",
    "    print(f'\\n\\tNumber of different configuration: {len(ch_config_dict)}\\n')\n",
    "else:\n",
    "    print('\\n>>> There is only one EOG configuration in your dataset! <<<')\n",
    "\n",
    "# # print info per channel configuaration\n",
    "# for i, (config, participants) in enumerate(ch_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Channels ({len(config)}) : {config}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0449b2ba-e7c7-4a85-9e24-77b5fa8dc212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b9fc70d29d482fa814eb9160feba80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='Selected configuration:', layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget to select the configuration of interest\n",
    "config_ch_slider = mk_config_slider(value = 1, min = 1, max = len(ch_config_dict))\n",
    "\n",
    "# print the configuration selected\n",
    "# interact with the slider output through the printing function \n",
    "widgets.interact(lambda i: print_config(i, config_dict=ch_config_dict, param=\"Channels\"), i=config_ch_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05198e3-a809-4bc4-a105-e9bfadf22695",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.3 Inspect EOG sampling frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d711eb5-b511-474e-9257-e2bcc6566fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> There is multiple sampling frequency for EOGs in your dataset! <<<\n",
      "\n",
      "\tNumber of different sampling frequency configuration: 3\n",
      "\n",
      "Quick overlook of the EOGs associated to sampling frequencies:\n",
      "\n",
      "256 Hz: ['EOG G' 'EOG D']\n",
      "\n",
      "400 Hz: ['EOG1' 'EOG2']\n",
      "\n",
      "128 Hz: ['EOG D' 'EOG G']\n"
     ]
    }
   ],
   "source": [
    "# the sampling frequency configuration\n",
    "sf_per_sub = df_eog.groupby('subject')['sampling_frequency'].apply(lambda x: tuple(sorted(set(x))))\n",
    "# identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "sf_config_dict = {}\n",
    "for config in sf_per_sub.unique():\n",
    "    sub = sf_per_sub[sf_per_sub == config].index.tolist()\n",
    "    sf_config_dict[config] = sub\n",
    "\n",
    "# print info per sf configuration (maybe print it only for multiple config)\n",
    "if len(sf_config_dict) > 1:\n",
    "    print('\\n>>> There is multiple sampling frequency for EOGs in your dataset! <<<')    \n",
    "    print(f'\\n\\tNumber of different sampling frequency configuration: {len(sf_config_dict)}\\n')\n",
    "    print('Quick overlook of the EOGs associated to sampling frequencies:')\n",
    "    for s, sf in enumerate(df_eog['sampling_frequency'].unique()):\n",
    "        # select only rows with the current sf\n",
    "        df_sf = df_eog[df_eog['sampling_frequency'] == sf].copy()\n",
    "        print(f'\\n{sf} Hz: {df_sf[\"channel\"].unique()}')\n",
    "else:\n",
    "    print(f'\\n>>> There is only one sampling frequency for EOGs in your dataset: {df_eog['sampling_frequency'].unique()} <<<')\n",
    "\n",
    "# print('\\nSampling frequency configurations:\\n')\n",
    "# for i, (config, participants) in enumerate(sf_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Sampling frequency ({len(config)}) : {config}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55beab23-6663-4f62-a590-610117b8a421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c117dcca1240ec9f62d142e109795b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='Selected configuration:', layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget to select the configuration of interest\n",
    "config_sf_slider = mk_config_slider(value = 1, min = 1, max = len(sf_config_dict))\n",
    "\n",
    "# print the configuration selected\n",
    "# interact with the slider output through the printing function \n",
    "widgets.interact(lambda i: print_config(i, config_dict=sf_config_dict, param=\"Sampling frequencies\"), i=config_sf_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a1db4-4830-4a4f-8688-13e06fda9857",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.4 Inspect EOG filtering parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d85f980-2ab7-455e-951a-e6371fe0ccb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Filtering parameters are not fully consistent across the dataset! <<<\n",
      "\n",
      "\tNumber of different EOG filters configurations: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if len(df_eog['highpass'].unique())+len(df_eog['lowpass'].unique())+len(df_eog['notch'].unique()) == 3:\n",
    "    print('\\n>>> All EOGs have the same filtering parameters! <<<')\n",
    "elif len(df_eog['highpass'].unique())+len(df_eog['lowpass'].unique())+len(df_eog['notch'].unique()) > 3:\n",
    "    print('\\n>>> Filtering parameters are not fully consistent across the dataset! <<<')\n",
    "else:\n",
    "    print('\\n>>> There may have been a problem in reading the filtering parameters. Here is the output: <<<')\n",
    "\n",
    "# Get the list of participants with different filtering parameters\n",
    "# 1st replace NaN because groupby does not like NaN\n",
    "df_filt = df_eog.copy()\n",
    "df_filt[['lowpass', 'highpass', 'notch']] = df_filt[['lowpass', 'highpass', 'notch']].fillna('missing')\n",
    "\n",
    "config_filters = (\n",
    "    df_filt.groupby(['lowpass', 'highpass', 'notch'])['subject']\n",
    "    .apply(lambda x: sorted(set(x)))\n",
    "    .reset_index(name = 'subjects')\n",
    ")\n",
    "\n",
    "# print filter configuration\n",
    "print(f'\\n\\tNumber of different EOG filters configurations: {len(config_filters)}\\n')\n",
    "# print('\\nFilters configurations: ')\n",
    "# r=1\n",
    "# for row in config_filters.itertuples(index=False):\n",
    "#     print(f'Configuration #{r} ({len(row.subjects)} participants)')\n",
    "#     print(f'highpass: {row.highpass}, lowpass: {row.lowpass}, notch: {row.notch}\\n')\n",
    "#     r=r+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01823f26-2f09-4cd9-9a6e-b46c84162081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a05523be4874bb8aeb7db53fb9eb999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='Selected configuration:', layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget to select the configuration of interest\n",
    "config_filter_slider = mk_config_slider(value = 1, min = 1, max = len(config_filters))\n",
    "\n",
    "# function to rpint filters configurations\n",
    "def print_filters(config_slider):\n",
    "    # get the info from the dataframe\n",
    "    idx = config_slider - 1\n",
    "    sID = config_filters.iloc[idx]['subjects']\n",
    "    hpass = config_filters.iloc[idx]['highpass']\n",
    "    lpass = config_filters.iloc[idx]['lowpass']\n",
    "    notch = config_filters.iloc[idx]['notch']\n",
    "    \n",
    "    # print info\n",
    "    print(f'Selected configuration: # {config_slider}')\n",
    "    print(f'\\tFilters configuration: highpass: {hpass}; lowpass: {lpass}; notch: {notch}')\n",
    "    print(f'\\t{len(sID)} participants: {sID}')\n",
    "\n",
    "widgets.interact(print_filters, config_slider = config_filter_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7b374f-a67d-4c2c-8d51-3d221131b8bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.5 Inspect EOG units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ead498f2-7177-4e47-8df5-01c69abdc55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Multiple units were found! <<<\n",
      "\n",
      "\tNumber of different units configurations: 3\n",
      "\n",
      "Quick overlook of channels associated to units:\n",
      "\n",
      "mV: ['EOG G' 'EOG D']\n",
      "\n",
      "UV: ['EOG1' 'EOG2']\n",
      "\n",
      "uV: ['EOG D' 'EOG G']\n"
     ]
    }
   ],
   "source": [
    "if len(df_eog['dimension'].unique()) == 1:\n",
    "    print(f'\\n>>> All EOGs have the same unit: {df_eog[\"dimension\"].unique()} <<<\\n')\n",
    "elif len(df_eog['dimension'].unique()) > 1:\n",
    "    print('\\n>>> Multiple units were found! <<<')\n",
    "    print(f'\\n\\tNumber of different EOG units configurations: {len(df_eog['dimension'].unique())}\\n')\n",
    "    print('Quick overlook of EOGs associated to units:')\n",
    "    for u, unit in enumerate(df_eog['dimension'].unique()):\n",
    "        # select only rows with the current sf\n",
    "        df_unit = df_eog[df_eog['dimension'] == unit].copy()\n",
    "        print(f'\\n{unit}: {df_unit[\"channel\"].unique()}')\n",
    "    \n",
    "\n",
    "# print the different configuration of units \n",
    "# if info about sf configuration is needed\n",
    "unit_per_sub = df_eog.groupby('subject')['dimension'].apply(lambda x: tuple(sorted(set(x))))\n",
    "ch_per_unit = df_eog.groupby('dimension')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "# identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "unit_config_dict = {}\n",
    "for config in unit_per_sub.unique():\n",
    "    sub = unit_per_sub[unit_per_sub == config].index.tolist()\n",
    "    unit_config_dict[config] = sub\n",
    "\n",
    "# print info per sf configuration\n",
    "# print('\\nUnits configurations:')\n",
    "# for i, (config, participants) in enumerate(unit_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Unit ({len(config)}) : {config}\\n')\n",
    "#     # print(f\"Participants : {participants}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "068c7788-7426-4c55-a262-cb0439e2ca01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7326d1b18a4b5f83c776f7d18ce84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='Selected configuration:', layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget to select the configuration of interest\n",
    "config_unit_slider = mk_config_slider(value = 1, min = 1, max = len(unit_config_dict))\n",
    "\n",
    "# print the configuration selected\n",
    "# interact with the slider output through the printing function \n",
    "widgets.interact(lambda i: print_config(i, config_dict=unit_config_dict, param=\"Units\"), i=config_unit_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f47a3b7-87c6-4e91-99e2-f9efda9e08a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.6 Inspect EOG signal inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b2c3906-fae3-4702-b6f8-8c6e9b8a3e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> No inverted polarity was detected in EOGs <<<\n",
      "\n",
      "Saving informations from EOG inverted polarity channels to:\n",
      "C:\\Users\\yvan.nedelec\\OneDrive - ICM\\Documents\\RE_yvan\\projects\\ICEBERG\\PSG/summary/EOG_inverted_polarity_edf.tsv \n",
      "(will be empty if no inverted polarity)\n"
     ]
    }
   ],
   "source": [
    "# select rows where the physical min is greater than the physical max\n",
    "df_inv = df_eog[df_eog['physical_min'] > df_eog['physical_max']]\n",
    "\n",
    "if not df_inv.empty:\n",
    "    print('\\n>>> Inverted polarity detected in EOGs! <<<')\n",
    "    print(f'{df_inv.shape[0]} EOGs have an inverted polarity (from {df_eog.shape[0]} EOGs in {len(edf_files)} edf files)')\n",
    "    print(df_inv[['subject', 'channel', 'dimension', 'physical_min', 'physical_max']])\n",
    "else:\n",
    "    print('\\n>>> No inverted polarity was detected in EOGs <<<')\n",
    "df_inv.to_csv(f'{summary_path}/EOG_inverted_polarity_edf.tsv', sep = '\\t')\n",
    "print(f'\\nSaving informations from inverted polarity EOGs to:\\n{summary_path}/EOG_inverted_polarity_edf.tsv \\n(will be empty if no inverted polarity)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e8713-eb68-4b0c-aa9c-75122905339b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.7 Inspect EOG resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f375f53-14ef-451a-9429-9e1a22f6dd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65b9e165c05464484af038873804a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedFloatText(value=0.1, description='Resolution threshold (uV):', layout=Layout(widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# res_theo have been converted to uV, but if dimension was not read or not indicated in the headers, it might not work. I might need to add something more robust\n",
    "r_thres = widgets.BoundedFloatText(\n",
    "    value=0.1,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    style={'description_width': '150px'},  # augmente la largeur de la description\n",
    "    layout=widgets.Layout(width='230px'),   # ajuste la taille totale du widget si besoin\n",
    "    description='Resolution threshold (uV):',\n",
    "    disabled=False\n",
    ");\n",
    "\n",
    "# define a function to interact with the widget\n",
    "def check_bad_res(threshold):\n",
    "    r_mask = df_eog['res_theoretical'] >= threshold\n",
    "    bad_res = df_eog[r_mask]\n",
    "    \n",
    "    if not bad_res.empty:\n",
    "        print(f'\\n>>> Poor resolution detected in EOGs! (>= {threshold} uV) <<<')\n",
    "        print(f'{bad_res.shape[0]} EOGs have a very poor resolution (from {df_eog.shape[0]} EOGs in {len(edf_files)} edf files)')\n",
    "        print(bad_res[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "    else:\n",
    "        print(f'\\n>>> No EOG with a poor resolution (>= {threshold} uV) was detected! <<<')\n",
    "    bad_res.to_csv(f'{summary_path}/EOG_bad_resolution_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from bad resolution EOGs to:\\n{summary_path}/EOG_bad_resolution_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "\n",
    "widgets.interact(check_bad_res, threshold=r_thres);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2096c3a-1f34-46ed-90d9-3a6505361380",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.8 Inspect EOG dynamic range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5911760-c9bd-4026-930b-f1753f68d638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73aa2c2988264d9cb871beebb9ac813e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedFloatText(value=400.0, description='Dynamic range threshold (uV):', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dr_thres = widgets.BoundedFloatText(\n",
    "    value=400,\n",
    "    min=0,\n",
    "    max=5000,\n",
    "    step=0.1,\n",
    "    style={'description_width': '200px'},  # augmente la largeur de la description\n",
    "    layout=widgets.Layout(width='270px'),   # ajuste la taille totale du widget si besoin\n",
    "    description='Dynamic range threshold (uV):',\n",
    "    disabled=False\n",
    ");\n",
    "\n",
    "\n",
    "def check_bad_dr(threshold):\n",
    "    dr_mask = df_eog['res_theoretical']*pow(2,16) <= threshold\n",
    "    bad_dr = df_eog[dr_mask]\n",
    "    \n",
    "    if not bad_dr.empty:\n",
    "        print(f'\\n>>> Small dynamic range detected in EOGs! (<= {threshold} uV) <<<\\n')\n",
    "        print(f'{bad_dr.shape[0]} EOGs have a small dynamic range (from {df_eog.shape[0]} EOGs in {len(edf_files)} edf files)')\n",
    "        print(bad_dr[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "    else:\n",
    "        print(f'\\n>>> No EOG with a small dynamic range(<= {threshold} uV) was detected! <<<')\n",
    "    bad_dr.to_csv(f'{summary_path}/EOG_bad_dynamic_range_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from bad dynamic range EOGs to:\\n{summary_path}/EOG_bad_dynamic_range_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "\n",
    "widgets.interact(check_bad_dr, threshold = dr_thres);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949e34f1-9a8c-4301-93b5-6d956d6d4b31",
   "metadata": {},
   "source": [
    "## 6. Inspect ECG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be6965c-43c1-49f8-bddd-b2163a2c5660",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.1 Select only ECGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d3a29cd-f142-4360-8a3e-481130dbad59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving informations from ECG channels to:\n",
      "C:\\Users\\yvan.nedelec\\OneDrive - ICM\\Documents\\RE_yvan\\projects\\ICEBERG\\PSG/summary/ECG_summary_table.tsv\n"
     ]
    }
   ],
   "source": [
    "# select only ECGs and return a warning if the number of participant is smaller/higher\n",
    "mask_ecg = df_full['channel'].str.contains(r'ecg', case = False, na=False) # create a mask that returns true for lines containing either ecg in the channel column\n",
    "df_ecg = df_full[mask_ecg]\n",
    "\n",
    "# Check if the number of participants with only ECG is the same as df_full. \n",
    "# If not, it might be because the transducer type was no correctly detected. \n",
    "# One possibility is to add the type of transducer to the condition line 2 of this cell.\n",
    "if len(df_full['subject'].unique()) > len(df_ecg['subject'].unique()):\n",
    "    # identify missing subjects\n",
    "    missing_sub = set(df_full['subject'].unique()) - set(df_ecg['subject'].unique())\n",
    "    print('\\n!!! There is less participants in the dataset with only ECGs !!!')\n",
    "    print(f'Missing participants: {missing_sub}')\n",
    "    print(\"\\nEither these participants don't have ECGs.\")\n",
    "    print(\"Or the transducer type was not correctly detected.\")\n",
    "    # get df of missing sub to save and inspect\n",
    "    df_ecgmiss = df_full[df_full['subject'].isin(missing_sub)]\n",
    "    df_ecgmiss.to_csv(f'{summary_path}/ECG_missing_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from missing participants to:\\n{summary_path}/ECG_missing_edf.tsv')\n",
    "    print('Please inspect the file, and specifically the column transducer_type')\n",
    "elif len(df_full['subject'].unique()) < len(df_ecg['subject'].unique()):\n",
    "    print('\\n!!! There is more participants in the dataset with only ECGs !!!')\n",
    "    print('This should not be the case.')\n",
    "    print('Please inspect what is happening in a code editor (spyder..), or ask Yvan.')\n",
    "    more_sub = set(df_ecg['subject'].unique()) - set(df_full['subject'].unique())\n",
    "    df_more = df_ecg[df_ecg['subject'].isin(more_sub)]\n",
    "    df_more.to_csv(f'{summary_path}/ECG_suspect_edf.csv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from suspect participants to:\\n{summary_path}/ECG_suspect_edf.tsv')\n",
    "\n",
    "# saving info from ECG\n",
    "df_ecg.to_csv(f'{summary_path}/ECG_summary_table.tsv', sep = '\\t')\n",
    "print(f'\\nSaving informations from ECGs to:\\n{summary_path}/ECG_summary_table.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f3b1c6-3ba4-4b8a-b367-54dd4413bc06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.2 Inspect ECG configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f545a1a-0906-4242-8422-db886f991089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> There is multiple ECG configurations in your dataset! <<<\n",
      "\n",
      "\tNumber of different ECG configuration: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the ECGs configuration per participant \n",
    "ch_per_sub = df_ecg.groupby('subject')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "\n",
    "# identify the ECG configuration of each participant and store them in a dict to print per ECG config\n",
    "ch_config_dict = {}\n",
    "for config in ch_per_sub.unique():\n",
    "    sub = ch_per_sub[ch_per_sub == config].index.tolist()\n",
    "    ch_config_dict[config] = sub\n",
    "\n",
    "if len(ch_config_dict) > 1:\n",
    "    print('\\n>>> There is multiple ECG configurations in your dataset! <<<')    \n",
    "    print(f'\\n\\tNumber of different ECG configuration: {len(ch_config_dict)}\\n')\n",
    "else:\n",
    "    print('\\n>>> There is only one ECG configuration in your dataset! <<<')\n",
    "\n",
    "# # print info per channel configuaration\n",
    "# for i, (config, participants) in enumerate(ch_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Channels ({len(config)}) : {config}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aaf05caa-f3b6-47e4-a470-3ef7cf439efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747138d30d3e422f88971c697d99e704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='Selected configuration:', layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget to select the configuration of interest\n",
    "config_ch_slider = mk_config_slider(value = 1, min = 1, max = len(ch_config_dict))\n",
    "\n",
    "# print the configuration selected\n",
    "# interact with the slider output through the printing function \n",
    "widgets.interact(lambda i: print_config(i, config_dict=ch_config_dict, param=\"Channels\"), i=config_ch_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e622e81-547c-4c3e-9833-e5ee79c3eee2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.3 Inspect ECG sampling frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee52a436-092d-40fa-b677-1eb011a4cda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> There is multiple sampling frequency for ECGs in your dataset! <<<\n",
      "\n",
      "\tNumber of different sampling frequency configuration: 3\n",
      "\n",
      "Quick overlook of the ECGs associated to sampling frequencies:\n",
      "\n",
      "256 Hz: ['ECG' 'ECG 1' 'ECG 2']\n",
      "\n",
      "128 Hz: ['ECG 1' 'ECG 2']\n",
      "\n",
      "400 Hz: ['ECG']\n"
     ]
    }
   ],
   "source": [
    "# the sampling frequency configuration\n",
    "sf_per_sub = df_ecg.groupby('subject')['sampling_frequency'].apply(lambda x: tuple(sorted(set(x))))\n",
    "# identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "sf_config_dict = {}\n",
    "for config in sf_per_sub.unique():\n",
    "    sub = sf_per_sub[sf_per_sub == config].index.tolist()\n",
    "    sf_config_dict[config] = sub\n",
    "\n",
    "# print info per sf configuration (maybe print it only for multiple config)\n",
    "if len(sf_config_dict) > 1:\n",
    "    print('\\n>>> There is multiple sampling frequency for ECGs in your dataset! <<<')    \n",
    "    print(f'\\n\\tNumber of different sampling frequency configuration: {len(sf_config_dict)}\\n')\n",
    "    print('Quick overlook of the ECGs associated to sampling frequencies:')\n",
    "    for s, sf in enumerate(df_ecg['sampling_frequency'].unique()):\n",
    "        # select only rows with the current sf\n",
    "        df_sf = df_ecg[df_ecg['sampling_frequency'] == sf].copy()\n",
    "        print(f'\\n{sf} Hz: {df_sf[\"channel\"].unique()}')\n",
    "else:\n",
    "    print(f'\\n>>> There is only one sampling frequency for ECGs in your dataset: {df_ecg['sampling_frequency'].unique()} <<<')\n",
    "\n",
    "# print('\\nSampling frequency configurations:\\n')\n",
    "# for i, (config, participants) in enumerate(sf_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Sampling frequency ({len(config)}) : {config}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7365d9b-95cf-40e9-b6b2-2c8bb80836fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddc94f07aa14257b6213d5714f0fa51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='Selected configuration:', layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget to select the configuration of interest\n",
    "config_sf_slider = mk_config_slider(value = 1, min = 1, max = len(sf_config_dict))\n",
    "\n",
    "# print the configuration selected\n",
    "# interact with the slider output through the printing function \n",
    "widgets.interact(lambda i: print_config(i, config_dict=sf_config_dict, param=\"Sampling frequencies\"), i=config_sf_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6aabf4-0bff-497c-b3f2-6ea68966bf76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.4 Inspect ECG filtering parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2353a752-9e29-4f05-beae-e6b08ccb82e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Filtering parameters are not fully consistent across the dataset! <<<\n",
      "\n",
      "\tNumber of different ECG filters configurations: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if len(df_ecg['highpass'].unique())+len(df_ecg['lowpass'].unique())+len(df_ecg['notch'].unique()) == 3:\n",
    "    print('\\n>>> All ECGs have the same filtering parameters! <<<')\n",
    "elif len(df_ecg['highpass'].unique())+len(df_ecg['lowpass'].unique())+len(df_ecg['notch'].unique()) > 3:\n",
    "    print('\\n>>> Filtering parameters are not fully consistent across the dataset! <<<')\n",
    "else:\n",
    "    print('\\n>>> There may have been a problem in reading the filtering parameters. Here is the output: <<<')\n",
    "\n",
    "# Get the list of participants with different filtering parameters\n",
    "# 1st replace NaN because groupby does not like NaN\n",
    "df_filt = df_ecg.copy()\n",
    "df_filt[['lowpass', 'highpass', 'notch']] = df_filt[['lowpass', 'highpass', 'notch']].fillna('missing')\n",
    "\n",
    "config_filters = (\n",
    "    df_filt.groupby(['lowpass', 'highpass', 'notch'])['subject']\n",
    "    .apply(lambda x: sorted(set(x)))\n",
    "    .reset_index(name = 'subjects')\n",
    ")\n",
    "\n",
    "# print filter configuration\n",
    "print(f'\\n\\tNumber of different ECG filters configurations: {len(config_filters)}\\n')\n",
    "# print('\\nFilters configurations: ')\n",
    "# r=1\n",
    "# for row in config_filters.itertuples(index=False):\n",
    "#     print(f'Configuration #{r} ({len(row.subjects)} participants)')\n",
    "#     print(f'highpass: {row.highpass}, lowpass: {row.lowpass}, notch: {row.notch}\\n')\n",
    "#     r=r+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a5f67fb-fbd8-4931-9ee1-07688b6d8eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a857a4cba546c48f9c7448c038d491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='Selected configuration:', layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget to select the configuration of interest\n",
    "config_filter_slider = mk_config_slider(value = 1, min = 1, max = len(config_filters))\n",
    "\n",
    "# function to rpint filters configurations\n",
    "def print_filters(config_slider):\n",
    "    # get the info from the dataframe\n",
    "    idx = config_slider - 1\n",
    "    sID = config_filters.iloc[idx]['subjects']\n",
    "    hpass = config_filters.iloc[idx]['highpass']\n",
    "    lpass = config_filters.iloc[idx]['lowpass']\n",
    "    notch = config_filters.iloc[idx]['notch']\n",
    "    \n",
    "    # print info\n",
    "    print(f'Selected configuration: # {config_slider}')\n",
    "    print(f'\\tFilters configuration: highpass: {hpass}; lowpass: {lpass}; notch: {notch}')\n",
    "    print(f'\\t{len(sID)} participants: {sID}')\n",
    "\n",
    "widgets.interact(print_filters, config_slider = config_filter_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a73596-3052-4332-a608-9e594331d3d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.5 Inspect ECG units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af19ed48-d5e8-4f71-9526-753137853b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Multiple units were found! <<<\n",
      "\n",
      "\tNumber of different units configurations: 2\n",
      "\n",
      "Quick overlook of channels associated to units:\n",
      "\n",
      "mV: ['ECG' 'ECG 1' 'ECG 2']\n",
      "\n",
      "MV: ['ECG']\n"
     ]
    }
   ],
   "source": [
    "if len(df_ecg['dimension'].unique()) == 1:\n",
    "    print(f'\\n>>> All ECGs have the same unit: {df_ecg[\"dimension\"].unique()} <<<\\n')\n",
    "elif len(df_ecg['dimension'].unique()) > 1:\n",
    "    print('\\n>>> Multiple units were found for ECGs! <<<')\n",
    "    print(f'\\n\\tNumber of different units configurations: {len(df_ecg['dimension'].unique())}\\n')\n",
    "    print('Quick overlook of ECGs associated to units:')\n",
    "    for u, unit in enumerate(df_ecg['dimension'].unique()):\n",
    "        # select only rows with the current sf\n",
    "        df_unit = df_ecg[df_ecg['dimension'] == unit].copy()\n",
    "        print(f'\\n{unit}: {df_unit[\"channel\"].unique()}')\n",
    "    \n",
    "\n",
    "# print the different configuration of units \n",
    "# if info about sf configuration is needed\n",
    "unit_per_sub = df_ecg.groupby('subject')['dimension'].apply(lambda x: tuple(sorted(set(x))))\n",
    "ch_per_unit = df_ecg.groupby('dimension')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "# identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "unit_config_dict = {}\n",
    "for config in unit_per_sub.unique():\n",
    "    sub = unit_per_sub[unit_per_sub == config].index.tolist()\n",
    "    unit_config_dict[config] = sub\n",
    "\n",
    "# print info per sf configuration\n",
    "# print('\\nUnits configurations:')\n",
    "# for i, (config, participants) in enumerate(unit_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Unit ({len(config)}) : {config}\\n')\n",
    "#     # print(f\"Participants : {participants}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e61ee8a-9dcc-4bf2-8368-2139f4cd0636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bce145a41542f1a158e25cd249531a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='Selected configuration:', layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget to select the configuration of interest\n",
    "config_unit_slider = mk_config_slider(value = 1, min = 1, max = len(unit_config_dict))\n",
    "\n",
    "# print the configuration selected\n",
    "# interact with the slider output through the printing function \n",
    "widgets.interact(lambda i: print_config(i, config_dict=unit_config_dict, param=\"Units\"), i=config_unit_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b079ce64-f923-4327-9798-fc00749a6bd4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.6 Inspect ECG signal inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d9d7cf6-35d4-4bf8-a0c6-1a23150521b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> No inverted polarity was detected in ECGs <<<\n",
      "\n",
      "Saving informations from ECG inverted polarity channels to:\n",
      "C:\\Users\\yvan.nedelec\\OneDrive - ICM\\Documents\\RE_yvan\\projects\\ICEBERG\\PSG/summary/ECG_inverted_polarity_edf.tsv \n",
      "(will be empty if no inverted polarity)\n"
     ]
    }
   ],
   "source": [
    "# select rows where the physical min is greater than the physical max\n",
    "df_inv = df_ecg[df_ecg['physical_min'] > df_ecg['physical_max']]\n",
    "\n",
    "if not df_inv.empty:\n",
    "    print('\\n>>> Inverted polarity detected in ECGs! <<<')\n",
    "    print(f'{df_inv.shape[0]} ECGs have an inverted polarity (from {df_ecg.shape[0]} ECGs in {len(edf_files)} edf files)')\n",
    "    print(df_inv[['subject', 'channel', 'dimension', 'physical_min', 'physical_max']])\n",
    "else:\n",
    "    print('\\n>>> No inverted polarity was detected in ECGs <<<')\n",
    "df_inv.to_csv(f'{summary_path}/ECG_inverted_polarity_edf.tsv', sep = '\\t')\n",
    "print(f'\\nSaving informations from inverted polarity ECGs to:\\n{summary_path}/ECG_inverted_polarity_edf.tsv \\n(will be empty if no inverted polarity)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd9c6f-5420-4013-bf02-6a0995c597f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.7 Inspect ECG resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96fa2a9b-abdb-4e9f-8fb2-dddf92280539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8c40e8e6f242bf8ed7ada20ccbbfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedFloatText(value=0.1, description='Resolution threshold (uV):', layout=Layout(widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# res_theo have been converted to uV, but if dimension was not read or not indicated in the headers, it might not work. I might need to add something more robust\n",
    "r_thres = widgets.BoundedFloatText(\n",
    "    value=0.1,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    style={'description_width': '150px'},  # augmente la largeur de la description\n",
    "    layout=widgets.Layout(width='230px'),   # ajuste la taille totale du widget si besoin\n",
    "    description='Resolution threshold (uV):',\n",
    "    disabled=False\n",
    ");\n",
    "\n",
    "# define a function to interact with the widget\n",
    "def check_bad_res(threshold):\n",
    "    r_mask = df_ecg['res_theoretical'] >= threshold\n",
    "    bad_res = df_ecg[r_mask]\n",
    "    \n",
    "    if not bad_res.empty:\n",
    "        print(f'\\n>>> Poor resolution detected in ECGs! (>= {threshold} uV) <<<')\n",
    "        print(f'{bad_res.shape[0]} ECGs have a very poor resolution (from {df_ecg.shape[0]} ecgs in {len(edf_files)} edf files)')\n",
    "        print(bad_res[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "    else:\n",
    "        print(f'\\n>>> No ECG with a poor resolution (>= {threshold} uV) was detected! <<<')\n",
    "    bad_res.to_csv(f'{summary_path}/ECG_bad_resolution_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from bad resolution ECGs to:\\n{summary_path}/ECG_bad_resolution_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "\n",
    "widgets.interact(check_bad_res, threshold=r_thres);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9047e4-c030-4c44-92de-a1b6f948ed99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.8 Inspect ECG dynamic range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1f97f77-0476-4ff4-83ee-c6cdea87a33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e078568591b048e19d33a34a4c21f270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedFloatText(value=400.0, description='Dynamic range threshold (uV):', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dr_thres = widgets.BoundedFloatText(\n",
    "    value=400,\n",
    "    min=0,\n",
    "    max=5000,\n",
    "    step=0.1,\n",
    "    style={'description_width': '200px'},  # augmente la largeur de la description\n",
    "    layout=widgets.Layout(width='270px'),   # ajuste la taille totale du widget si besoin\n",
    "    description='Dynamic range threshold (uV):',\n",
    "    disabled=False\n",
    ");\n",
    "\n",
    "\n",
    "def check_bad_dr(threshold):\n",
    "    dr_mask = df_ecg['res_theoretical']*pow(2,16) <= threshold\n",
    "    bad_dr = df_ecg[dr_mask]\n",
    "    \n",
    "    if not bad_dr.empty:\n",
    "        print(f'\\n>>> Small dynamic range detected in ECGs! (<= {threshold} uV) <<<\\n')\n",
    "        print(f'{bad_dr.shape[0]} ECGs have a small dynamic range (from {df_ecg.shape[0]} ECGs in {len(edf_files)} edf files)')\n",
    "        print(bad_dr[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "    else:\n",
    "        print(f'\\n>>> No ECG with a small dynamic range(<= {threshold} uV) was detected! <<<')\n",
    "    bad_dr.to_csv(f'{summary_path}/ECG_bad_dynamic_range_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from bad dynamic range ECGs to:\\n{summary_path}/ECG_bad_dynamic_range_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "\n",
    "widgets.interact(check_bad_dr, threshold = dr_thres);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
