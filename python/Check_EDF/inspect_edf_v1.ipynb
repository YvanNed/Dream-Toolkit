{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12bcc77e-a10a-441b-b8e9-33006dd75aee",
   "metadata": {},
   "source": [
    "# Check export parameters from .edf files of an EEG database\n",
    "---\n",
    "EDF is the european data format for storage of multichannel biological and physical signals (EEG/EMG/ECG.. but also intracranial data https://www.edfplus.info/ \\\n",
    "It was published in 1992, and an updgraded version in 2003 (to add possibilities of discontinuous recordings, annotations, stimuli and events in a UTF-8 format). \\\n",
    "It is a compressed 16-bit format (meaning that each measured data point can take 2^16 values between the min/max of a dynamic range.\n",
    "\n",
    "---\n",
    "At the exportation in the .edf format (with software like compumedics), many parameters need to be set per recorded channels, such as the channels configuration, sampling frequency, filtering, units, dynamic range. \\\n",
    "Exporting as .edf format is tedious and time consuming, and mistakes in parameters can easily be made.  \\\n",
    "To avoid making mistakes, there is the possibility of implmenting routines within some softwares (insert a link of how to make a routine in compumedic). \\\n",
    "Inspecting those parameters can also be necessary if you want to work on an already existing dataset, to make sure that every participant's data is exploitable. \n",
    "\n",
    "---\n",
    "The script directly reads information from headers of the .edf files, instead of relying on existing packages such as MNE python or pyedflib.  \\\n",
    "MNE python is not returning all the informations from headers (such as boundaries of dynamic range, filtering parameters if there are different filters for different channel types).\\\n",
    "pyedflib is too rigid and some headers are not read (in the ICEBERG database at least).\\\n",
    "\\\n",
    "To use this notebook, read markdown cells, then run code cells and read the ouput below.\n",
    "**The script will save summary dataframes as .tsv file so that you can visually inspect (or reload later) if needed.** Those summaries will be stored in a summary folder within the study folder. \\\n",
    "\\\n",
    "\\\n",
    "It was developped on the ICEBERG database and tested on APOMORPHEE (from No√©mie's internship).  \\\n",
    "last update 30/06/2025, YN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316eaf2b-5591-4698-968d-5117df3f8b13",
   "metadata": {},
   "source": [
    "## 0. Import packages and define custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d7e8e-b926-4914-97ee-92f4b39567fc",
   "metadata": {},
   "source": [
    "If you are missing one package (getting an error when you import it), there is two solutions: \\\n",
    "1. Install within jupyter notebook:\n",
    "- run in a new cell \"%conda install nom_du_package --yes\"\n",
    "- re-run the import cell\n",
    "\n",
    "2. Install within a terminal: \n",
    "- go back to your terminal\n",
    "- enter the virtual environment you are working in (from where you installed jupyter notebook) with \"conda activate my_virtual_environment\"\n",
    "- run: \"conda install -k my_package\"\n",
    "- restart the kernel of the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5411d73d-c71c-433d-81d2-169e69bd00ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import re\n",
    "from ipyfilechooser import FileChooser\n",
    "import ipywidgets as widgets\n",
    "import warnings\n",
    "\n",
    "# custom function to detect automatically and return the encoding of edf file (from chatGPT)\n",
    "def detect_encoding(byte_string, min_confidence=0.6):\n",
    "    result = chardet.detect(byte_string)\n",
    "    encoding = result['encoding']\n",
    "    confidence = result['confidence']\n",
    "    if encoding is None or confidence < min_confidence:\n",
    "        raise UnicodeDecodeError(\"chardet\", byte_string, 0, len(byte_string),\n",
    "                                 f\"\\tUnable to reliably detect encoding. Detected: {encoding} with confidence {confidence}\")\n",
    "    return encoding\n",
    "\n",
    "# custom function to read information from EDF headers, without using the pyedflib package (that was too strict for ICEBERG)\n",
    "# EDF file should follow a strict format dedicating specific number of octets for each type of information.\n",
    "# it means that we can read the info octect by octet by specifying the number of octet we expect for the next variable (that is known from the EDF norm)\n",
    "def read_edf_header_custom(file_path):\n",
    "    with open(file_path, 'rb') as f: # open the file in binary mode, to read octet by octet. \n",
    "        header = {}\n",
    "        # detect encoding\n",
    "        raw_header = f.read(256)\n",
    "        encoding = detect_encoding(raw_header)\n",
    "        print(f\"\\tDetected encoding for {file_path} : {encoding}\")\n",
    "        # Rewind to beginning\n",
    "        f.seek(0)\n",
    "        \n",
    "        # the first 256 octets are subject global info\n",
    "        header['version'] = f.read(8).decode(encoding).strip()\n",
    "        header['patient_id'] = f.read(80).decode(encoding).strip()\n",
    "        header['recording_id'] = f.read(80).decode(encoding).strip()\n",
    "        header['start_date'] = f.read(8).decode(encoding).strip()\n",
    "        header['start_time'] = f.read(8).decode(encoding).strip()\n",
    "        header['header_bytes'] = int(f.read(8).decode(encoding).strip())\n",
    "        header['reserved'] = f.read(44).decode(encoding).strip()\n",
    "        header['n_data_records'] = int(f.read(8).decode(encoding).strip())\n",
    "        header['duration_data_record'] = float(f.read(8).decode(encoding).strip())\n",
    "        header['n_channels'] = int(f.read(4).decode(encoding).strip())\n",
    "        \n",
    "        # get info per channel\n",
    "        n = header['n_channels']\n",
    "        channel_fields = {\n",
    "            'channel': [],\n",
    "            'transducer_type': [],\n",
    "            'dimension': [],\n",
    "            'physical_min': [],\n",
    "            'physical_max': [],\n",
    "            'digital_min': [],\n",
    "            'digital_max': [],\n",
    "            'prefiltering': [],\n",
    "            'sampling_frequency': [],\n",
    "            'reserved': [],\n",
    "        }\n",
    "\n",
    "        for key in channel_fields:\n",
    "            length = {\n",
    "                'channel': 16,\n",
    "                'transducer_type': 80,\n",
    "                'dimension': 8,\n",
    "                'physical_min': 8,\n",
    "                'physical_max': 8,\n",
    "                'digital_min': 8,\n",
    "                'digital_max': 8,\n",
    "                'prefiltering': 80,\n",
    "                'sampling_frequency': 8,\n",
    "                'reserved': 32,\n",
    "            }[key]\n",
    "            channel_fields[key] = [f.read(length).decode(encoding).strip() for _ in range(n)]\n",
    "\n",
    "        header.update(channel_fields)\n",
    "    \n",
    "    return header\n",
    "\n",
    "# function to extract filters information from the string in headers\n",
    "def extract_filter_value(s, tag):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    match = re.search(rf'{tag}[:\\s]*([\\d\\.]+)\\s*', s, re.IGNORECASE)\n",
    "    return float(match.group(1)) if match else None\n",
    "\n",
    "# custom function to get the sampling frequency out of a dataframe (the df needs to have 'subject' and 'channel' as column)\n",
    "def get_sf(df, subject, channel):\n",
    "    df_sf = df[(df['subject'] == subject) & (df['channel'] == channel)]\n",
    "    if not df_sf.empty:\n",
    "        return df_sf.iloc[0]['sampling_frequency']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# function to create a widget slider to select configuration to inspect\n",
    "def mk_config_slider(value = 1, min = 1, max = 5):\n",
    "    config_slider = widgets.IntSlider(\n",
    "    value=value,\n",
    "    min=min,\n",
    "    max=max,\n",
    "    step=1,\n",
    "    description='Selected configuration:',\n",
    "    style={'description_width': '150px'},  # augmente la largeur de la description\n",
    "    layout=widgets.Layout(width='400px'),   # ajuste la taille totale du widget si besoin\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    "    )\n",
    "    return config_slider\n",
    "\n",
    "# function to print the configuration of a dataset parameter\n",
    "def print_config(i, config_dict, param):\n",
    "    # get the key and value from dictionnary\n",
    "    idx = i - 1\n",
    "    # get participant ID\n",
    "    value = list(config_dict.values())  \n",
    "    v = value[idx]  \n",
    "    # get configuration\n",
    "    key = list(config_dict.keys())\n",
    "    k = key[idx]\n",
    "    \n",
    "    # print info\n",
    "    print(f'Selected configuration: # {i}')\n",
    "    print(f'\\t{param}: {k}')\n",
    "    print(f'\\t{len(v)} participants: {v}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c9a604-7fe3-4a81-9e60-1587f7cb14e1",
   "metadata": {},
   "source": [
    "## 1. Select data folder and get the file list of your database\n",
    "The first cell below will open a widget to select the folder containing your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9124017c-7f30-4794-aab6-55a462a5b85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8209d54da6d4f20bd306d5f3a47f864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/thandrillon/WorkGit/Dream-Toolkit/python/Check_EDF', filename='', title='<b>Choose yo‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chooser = FileChooser(os.getcwd())\n",
    "chooser.title = \"<b>Choose your study folder</b>\"\n",
    "chooser.show_only_dirs = True\n",
    "display(chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79170e5c-91e6-48ca-84fa-1b457eae1215",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = chooser.selected_path\n",
    "\n",
    "# get the edf file list \n",
    "edf_files = list(Path(folder_path).rglob('*.edf'))\n",
    "\n",
    "# initialyse list of dataframe to store file info, that will be concatenated at the end (this is better for performance)\n",
    "df_list = []\n",
    "\n",
    "# check the existence and/or create the summary folder that will receive the summary tables and the report\n",
    "summary_path = f'{folder_path}/summary'\n",
    "if not os.path.exists(summary_path):\n",
    "    os.makedirs(summary_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe7e801-ae24-4fdd-a177-a2cbd95e4595",
   "metadata": {},
   "source": [
    "## 2. Loop over the edf file list to extract parameters from each participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb6870b-badd-4225-aaef-fc974516dee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file 1/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/17_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/17_N2.edf : ascii\n",
      "file 2/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/21_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/21_N2.edf : ascii\n",
      "file 3/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/2_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/2_N1.edf : ascii\n",
      "file 4/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/33_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/33_N2.edf : ascii\n",
      "file 5/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/17_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/17_N1.edf : ascii\n",
      "file 6/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/21_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/21_N1.edf : ascii\n",
      "file 7/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/2_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/2_N2.edf : ascii\n",
      "file 8/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/33_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/33_N1.edf : ascii\n",
      "file 9/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/15_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/15_N1.edf : ascii\n",
      "file 10/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/19_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/19_N1.edf : ascii\n",
      "file 11/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/31_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/31_N1.edf : ascii\n",
      "file 12/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/23_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/23_N1.edf : ascii\n",
      "file 13/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/15_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/15_N2.edf : ascii\n",
      "file 14/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/19_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/19_N2.edf : ascii\n",
      "file 15/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/31_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/31_N2.edf : ascii\n",
      "file 16/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/23_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/23_N2.edf : ascii\n",
      "file 17/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/4_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/4_N2.edf : ascii\n",
      "file 18/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/8_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/8_N2.edf : ascii\n",
      "file 19/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/11_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/11_N1.edf : ascii\n",
      "file 20/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/4_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/4_N1.edf : ascii\n",
      "file 21/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/8_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/8_N1.edf : ascii\n",
      "file 22/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/11_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/11_N2.edf : ascii\n",
      "file 23/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/29_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/29_N2.edf : ascii\n",
      "file 24/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/6_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/6_N1.edf : ascii\n",
      "file 25/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/25_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/25_N2.edf : ascii\n",
      "file 26/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/13_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/13_N2.edf : ascii\n",
      "file 27/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/29_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/29_N1.edf : ascii\n",
      "file 28/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/6_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/6_N2.edf : ascii\n",
      "file 29/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/25_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/25_N1.edf : ascii\n",
      "file 30/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/13_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/13_N1.edf : ascii\n",
      "file 31/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/3_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/3_N2.edf : ascii\n",
      "file 32/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/20_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/20_N1.edf : ascii\n",
      "file 33/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/32_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/32_N1.edf : ascii\n",
      "file 34/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/16_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/16_N1.edf : ascii\n",
      "file 35/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/3_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/3_N1.edf : ascii\n",
      "file 36/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/20_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/20_N2.edf : ascii\n",
      "file 37/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/32_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/32_N2.edf : ascii\n",
      "file 38/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/16_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/16_N2.edf : ascii\n",
      "file 39/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/30_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/30_N2.edf : ascii\n",
      "file 40/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/1_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/1_N1.edf : ascii\n",
      "file 41/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/22_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/22_N2.edf : ascii\n",
      "file 42/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/14_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/14_N2.edf : ascii\n",
      "file 43/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/18_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/18_N2.edf : ascii\n",
      "file 44/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/30_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/30_N1.edf : ascii\n",
      "file 45/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/1_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/1_N2.edf : ascii\n",
      "file 46/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/22_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/22_N1.edf : ascii\n",
      "file 47/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/14_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/14_N1.edf : ascii\n",
      "file 48/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/18_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/18_N1.edf : ascii\n",
      "file 49/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/10_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/10_N2.edf : ascii\n",
      "file 50/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/26_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/26_N2.edf : ascii\n",
      "file 51/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/5_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/5_N1.edf : ascii\n",
      "file 52/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/34_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/34_N2.edf : ascii\n",
      "file 53/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/9_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/9_N1.edf : ascii\n",
      "file 54/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/10_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/10_N1.edf : ascii\n",
      "file 55/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/26_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/26_N1.edf : ascii\n",
      "file 56/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/5_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/5_N2.edf : ascii\n",
      "file 57/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/34_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/34_N1.edf : ascii\n",
      "file 58/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/9_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/9_N2.edf : ascii\n",
      "file 59/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/12_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/12_N1.edf : ascii\n",
      "file 60/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/28_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/28_N1.edf : ascii\n",
      "file 61/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/7_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/7_N2.edf : ascii\n",
      "file 62/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/12_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/12_N2.edf : ascii\n",
      "file 63/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/28_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/28_N2.edf : ascii\n",
      "file 64/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/7_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/7_N1.edf : ascii\n",
      "file 65/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/bin/27_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/bin/27_N1.edf : ascii\n",
      "file 66/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/bin/27_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/bin/27_N2.edf : ascii\n",
      "file 67/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/bin/24_N1.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/bin/24_N1.edf : ascii\n",
      "file 68/68, currently opening file: /Users/thandrillon/Data/Apomorphee/data/bin/24_N2.edf\n",
      "\tDetected encoding for /Users/thandrillon/Data/Apomorphee/data/bin/24_N2.edf : ascii\n",
      "\n",
      "Saving full informations from headers of the dataset to:\n",
      "/Users/thandrillon/Data/Apomorphee/data/summary/full_summary_table_edf.tsv\n"
     ]
    }
   ],
   "source": [
    "# intialyse empty list for file that could not be read\n",
    "failed_list = []\n",
    "\n",
    "for e, edf_path in enumerate(edf_files):\n",
    "    print(f'file {e+1}/{len(edf_files)}, currently opening file: {edf_path}')\n",
    "    # read file with the custom function\n",
    "    try:\n",
    "        edf_header = read_edf_header_custom(edf_path) \n",
    "        \n",
    "        # get subject name (corresponding to file_name)\n",
    "        sub_name = edf_path.stem\n",
    "        \n",
    "        # get subject group (from the parent folder, in ICEBERG database subfolder were created per patient group)\n",
    "        sub_folder = edf_path.parent.name # get the parent folder of the subject file (path)\n",
    "        \n",
    "        # create df from signal info\n",
    "        df = pd.DataFrame(edf_header)\n",
    "            \n",
    "        # theoretical resolution (edf are 16bit files so the eeg signal can take 2^16 values within the dynamic range)\n",
    "        df['res_theoretical'] = (abs(pd.to_numeric(df['physical_min']))+abs(pd.to_numeric(df['physical_max'])))/pow(2,16)\n",
    "        # turn theoretical resolution to uV if dimension is mV (if no dimension, it is a mess)\n",
    "        df.loc[df['dimension'].str.contains('mv', case=False, na=False), 'res_theoretical'] *= 1000\n",
    "        \n",
    "        # get filtering info in different columns\n",
    "        df['lowpass']   = df['prefiltering'].apply(lambda x: extract_filter_value(x, 'LP'))\n",
    "        df['highpass']  = df['prefiltering'].apply(lambda x: extract_filter_value(x, 'HP'))\n",
    "        df['notch']  = df['prefiltering'].apply(lambda x: extract_filter_value(x, 'NOTCH'))\n",
    "        \n",
    "        # add subject info in the dataframe\n",
    "        df['subject'] = sub_name\n",
    "        df['group'] = sub_folder\n",
    "        df['path'] = str(edf_path)\n",
    "        \n",
    "        # select only the columns of interest\n",
    "        df = df[['subject', 'group', 'path', 'channel', 'transducer_type', 'dimension', 'sampling_frequency', \n",
    "             'highpass', 'lowpass', 'notch', 'physical_min', 'physical_max', 'res_theoretical']]\n",
    "        \n",
    "        # store subject data\n",
    "        df_list.append(df)\n",
    "\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"[‚ö†Ô∏è] Encoding problem for {edf_path}\")\n",
    "        failed_list.append((edf_path, 'encoding'))\n",
    "    except Exception as e:\n",
    "        print(f\"[‚ùå] Unkown problem for {edf_path} : {e}\")\n",
    "        failed_list.append((edf_path, 'other'))\n",
    "   \n",
    "# concatenate dataframe into one and only\n",
    "with warnings.catch_warnings(): # this is to skip a warning not affecting our operation\n",
    "    warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "    df_full = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# save summary table containing full info\n",
    "df_full.to_csv(f'{summary_path}/full_summary_table_edf.tsv', sep = '\\t')\n",
    "print(f'\\nSaving full informations from headers of the dataset to:\\n{summary_path}/full_summary_table_edf.tsv')\n",
    "\n",
    "# save the failed list if not empty:\n",
    "failed_df = pd.DataFrame(failed_list)\n",
    "if not failed_df.empty:\n",
    "    failed_df.to_csv(f'{summary_path}/failed_edf_read.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving the list of files that could not be read to: \\n{summary_path}/failed_edf_read.tsv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe23577-f4c7-4616-944c-322ac7d83552",
   "metadata": {},
   "source": [
    "## 3. Inspect dataset general info (# participants, groups, recorded sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b1f65f0-5aa2-471f-9ce3-12090834744c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> There is 68 participants in your dataset, within 2 group(s): ['data' 'bin'] <<<\n",
      "       n_subjects\n",
      "group            \n",
      "bin             4\n",
      "data           64\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n>>> There is {len(df_full[\"subject\"].unique())} participants in your dataset, within {len(df_full[\"group\"].unique())} group(s): {df_full[\"group\"].unique()} <<<')\n",
    "print(df_full.drop_duplicates().groupby('group').agg(n_subjects=('subject', 'nunique')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdf3b8b8-fdc9-4b34-abef-5cbaab4a1f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full recorded sensors configuration of your database (across participants): \n",
      "F4-M1\n",
      "C4-M1\n",
      "C3-M2\n",
      "O2-M1\n",
      "EMG_L\n",
      "ECG\n",
      "Ronfl\n",
      "Flux\n",
      "Therm\n",
      "Thor\n",
      "Abdo\n",
      "Sum\n",
      "SpO2\n",
      "FC\n",
      "Pos\n",
      "Jambe_R\n",
      "Jambe_L\n",
      "EDF Annotations\n",
      "F4\n",
      "C3\n",
      "C4\n",
      "O2\n",
      "M1\n",
      "M2\n",
      "Chin1\n",
      "Chin2\n",
      "ECG1\n",
      "ECG2\n",
      "Fp1\n",
      "O1\n",
      "A2\n",
      "EOG G\n",
      "EOG D\n",
      "EMG 1\n",
      "EMG 2\n",
      "EMG JD\n",
      "EMG JG\n",
      "Mic\n",
      "Thermistance\n",
      "Thoracic\n",
      "Abdominal\n",
      "Pulse\n",
      "Pleth\n",
      "Position\n",
      "EEG F2\n",
      "EEG C4\n",
      "EEG O2\n",
      "EEG T4\n",
      "EEG F1\n",
      "EEG C3\n",
      "EEG O1\n",
      "EEG T3\n",
      "EEG A2\n",
      "MO-D\n",
      "MO-G\n",
      "MENTON\n",
      "JAM-Dt\n",
      "JAM-Ga\n",
      "SAT\n",
      "ABD\n",
      "THO\n",
      "RONF\n",
      "PRES\n",
      "THERM\n",
      "PTT\n",
      "Pouls\n",
      "FCbb\n",
      "POS\n",
      "E1-M2\n",
      "E2-M2\n",
      "F3-M2\n",
      "O1-M2\n",
      "EMG_R\n",
      "Pl?th\n",
      "E1\n",
      "E2\n",
      "F3\n",
      "Chin3\n",
      "LLeg1-LLeg2\n",
      "RLeg1-RLeg2\n"
     ]
    }
   ],
   "source": [
    "print('\\nFull recorded sensors configuration of your database (across participants): ')\n",
    "print(*df_full['channel'].unique(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4bf662-62bb-4046-a98b-8298c117276f",
   "metadata": {},
   "source": [
    "## 4. Inspect EEG and EOG channels only "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020e2fd-b7ec-4249-a53a-f010f38ffcc9",
   "metadata": {},
   "source": [
    "### 4.1 Select only the EEG/EOG channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c434167-29d3-4fd0-894e-8438c8ff5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only EEG and EOG channels and return a warning if the number of participant is smaller/higher\n",
    "mask_ch = df_full['transducer_type'].str.contains(r'EEG|EOG|AGAGCL ELECTRODE', na=False) # create a mask that returns true for lines containing either EEG/EOG/EMG/ECG in the transducer_type column\n",
    "df_ch = df_full[mask_ch]\n",
    "# remove the emg channels that were captured with the AGAGCL ELECTRODE transducer type \n",
    "df_ch = df_ch[~df_ch['channel'].str.contains(r'emg|ecg', case=False, na=False)] # the ~ allows to not select the selection (like ! in matlab)\n",
    "\n",
    "# Check if the number of participants with only EEG/EOG is the same as df_full. \n",
    "# If not, it might be because the transducer type was no correctly detected. \n",
    "# One possibility is to add the type of transducer to the condition line 2 of this cell.\n",
    "if len(df_full['subject'].unique()) > len(df_ch['subject'].unique()):\n",
    "    # identify missing subjects\n",
    "    missing_sub = set(df_full['subject'].unique()) - set(df_ch['subject'].unique())\n",
    "    print('\\n!!! There is less participants in the dataset with only EEG/EOG channels !!!')\n",
    "    print(f'Missing participants: {missing_sub}')\n",
    "    print(\"\\nEither these participants don't have EEG/EOG channel.\")\n",
    "    print(\"Or the transducer type was not correctly detected.\")\n",
    "    # get df of missing sub to save and inspect\n",
    "    df_miss = df_full[df_full['subject'].isin(missing_sub)]\n",
    "    df_miss.to_csv(f'{summary_path}/EEG-EOG_missing_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from missing participants to:\\n{summary_path}/EEG-EOG_missing_edf.tsv')\n",
    "    print('Please inspect the file, and specifically the column transducer_type')\n",
    "elif len(df_full['subject'].unique()) < len(df_ch['subject'].unique()):\n",
    "    print('\\n!!! There is more participants in the dataset with only EEG/EOG channels !!!')\n",
    "    print('This should not be the case.')\n",
    "    print('Please inspect what is happening in a code editor (spyder..), or ask Yvan.')\n",
    "    more_sub = set(df_ch['subject'].unique()) - set(df_full['subject'].unique())\n",
    "    df_more = df_ch[df_ch['subject'].isin(more_sub)]\n",
    "    df_more.to_csv(f'{summary_path}/EEG-EOG_suspect_edf.csv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from suspect participants to:\\n{summary_path}/EEG-EOG_suspect_edf.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a752f46-632f-4120-b905-f32a26a4d6cc",
   "metadata": {},
   "source": [
    "### 4.2 Inspect EEG/EOG channels configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7373270-1a31-4919-baf8-349c0fa408b5",
   "metadata": {},
   "source": [
    "There will be likely many channels configuration (especially with multicentric dataset).  \\\n",
    "\\\n",
    "For polysomnographic EEG, there should be at least:\n",
    "- 4 EEG (Fp1, C3, O1 and A2 that will be used as the reference) (or less frequently Fp2, C4, O2 and A1) \\\n",
    "- 2 EOG (EOG D, EOG G)\n",
    "\n",
    "Depending on the analysis you plan, if one configuration does not contain those electrodes you will need either to re-export the data or to exclude the participant. \\\n",
    "\\\n",
    "If the channel label is Fp1-A2, it means that your data is already re-referenced to A2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "994eb7b0-4742-4d3c-94f0-36b34b2b065b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> There is multiple channels configurations in your dataset! <<<\n",
      "\n",
      "\n",
      "Number of different channels configuration: 9\n",
      "\n",
      "Configuration #1 (26 participants):\n",
      "Channels (6) : ('A2', 'C3', 'EOG D', 'EOG G', 'Fp1', 'O1')\n",
      "\n",
      "Configuration #2 (2 participants):\n",
      "Channels (6) : ('C3-M2', 'C4-M1', 'E1-M2', 'E2-M2', 'F4-M1', 'O2-M1')\n",
      "\n",
      "Configuration #3 (13 participants):\n",
      "Channels (4) : ('C3-M2', 'C4-M1', 'F4-M1', 'O2-M1')\n",
      "\n",
      "Configuration #4 (7 participants):\n",
      "Channels (6) : ('C3', 'C4', 'F4', 'M1', 'M2', 'O2')\n",
      "\n",
      "Configuration #5 (6 participants):\n",
      "Channels (8) : ('C3-M2', 'C4-M1', 'E1-M2', 'E2-M2', 'F3-M2', 'F4-M1', 'O1-M2', 'O2-M1')\n",
      "\n",
      "Configuration #6 (2 participants):\n",
      "Channels (10) : ('C3', 'C4', 'E1', 'E2', 'F3', 'F4', 'M1', 'M2', 'O1', 'O2')\n",
      "\n",
      "Configuration #7 (1 participants):\n",
      "Channels (6) : ('C3-M2', 'C4-M1', 'F3-M2', 'F4-M1', 'O1-M2', 'O2-M1')\n",
      "\n",
      "Configuration #8 (1 participants):\n",
      "Channels (8) : ('C3', 'C4', 'F3', 'F4', 'M1', 'M2', 'O1', 'O2')\n",
      "\n",
      "Configuration #9 (10 participants):\n",
      "Channels (9) : ('EEG A2', 'EEG C3', 'EEG C4', 'EEG F1', 'EEG F2', 'EEG O1', 'EEG O2', 'EEG T3', 'EEG T4')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the channels configuration per participant \n",
    "ch_per_sub = df_ch.groupby('subject')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "\n",
    "# identify the channel configuration of each participant and store them in a dict to print per channel config\n",
    "ch_config_dict = {}\n",
    "for config in ch_per_sub.unique():\n",
    "    sub = ch_per_sub[ch_per_sub == config].index.tolist()\n",
    "    ch_config_dict[config] = sub\n",
    "\n",
    "if len(ch_config_dict) > 1:\n",
    "    print('\\n>>> There is multiple channels configurations in your dataset! <<<')    \n",
    "    print(f'\\n\\nNumber of different channels configuration: {len(ch_config_dict)}\\n')\n",
    "else:\n",
    "    print('\\n>>> There is only one channels configuration in your dataset! <<<')\n",
    "\n",
    "# # print info per channel configuaration\n",
    "# for i, (config, participants) in enumerate(ch_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Channels ({len(config)}) : {config}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c6905-ebf9-4b4d-ae5e-6b210dcc4546",
   "metadata": {},
   "source": [
    "To inspect the participants ID in one configuration, run the cell just below after changing the parameter  \"configuration_to_inspect\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "233e9c0b-321f-420d-8161-53561474be52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d67ef291ba4e418ba070f8c2bc79a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='Selected configuration:', layou‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget to select the configuration of interest\n",
    "config_ch_slider = mk_config_slider(value = 1, min = 1, max = len(ch_config_dict))\n",
    "\n",
    "# print the configuration selected\n",
    "# interact with the slider output through the printing function \n",
    "widgets.interact(lambda i: print_config(i, config_dict=ch_config_dict, param=\"Channels\"), i=config_ch_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a7e4c3-6e5a-4b05-98e3-2183bf7b0e25",
   "metadata": {},
   "source": [
    "### 4.3 Inspect sampling frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f44f5-bc03-46f7-ae35-401ec0e3ab12",
   "metadata": {},
   "source": [
    "Ideally, you expect to have only one sampling frequency for all the channels and participants. \\\n",
    "In practice, you might have different sampling frequencies across participants (especially with multicentric dataset), and 2 sampling frequency within participants (one for EEG, the other for EOG).  \\\n",
    "\\\n",
    "Each EEG analysis software handles multiple sampling frequencies within participants differently. For example:\n",
    "- MNE python will automatically upsample channels to the highest sampling frequency\n",
    "- Fieldtrip will load only a subset of channels (with the sampling frequency the most represented)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87a23e13-8c7f-4cb1-af1d-a97a5b828e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> There is multiple sampling frequency configurations in your dataset! <<<\n",
      "\n",
      "\n",
      "Number of different sampling frequency configuration: 4\n",
      "\n",
      "\n",
      "Sampling frequency configurations:\n",
      "\n",
      "Configuration #1 (37 participants):\n",
      "Sampling frequency (1) : ('256',)\n",
      "\n",
      "Configuration #2 (21 participants):\n",
      "Sampling frequency (1) : ('200',)\n",
      "\n",
      "Configuration #3 (9 participants):\n",
      "Sampling frequency (1) : ('512',)\n",
      "\n",
      "Configuration #4 (1 participants):\n",
      "Sampling frequency (2) : ('128', '256')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the sampling frequency configuration\n",
    "sf_per_sub = df_ch.groupby('subject')['sampling_frequency'].apply(lambda x: tuple(sorted(set(x))))\n",
    "# identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "sf_config_dict = {}\n",
    "for config in sf_per_sub.unique():\n",
    "    sub = sf_per_sub[sf_per_sub == config].index.tolist()\n",
    "    sf_config_dict[config] = sub\n",
    "\n",
    "# print info per sf configuration (maybe print it only for multiple config)\n",
    "if len(sf_config_dict) > 1:\n",
    "    print('\\n>>> There is multiple sampling frequency configurations in your dataset! <<<')    \n",
    "    print(f'\\n\\nNumber of different sampling frequency configuration: {len(sf_config_dict)}\\n')\n",
    "    for s, sf in enumerate(df_ch['sampling_frequency'].unique()):\n",
    "        # select only rows with the current sf\n",
    "        df_sf = df_ch[df_ch['sampling_frequency'] == sf].copy()\n",
    "        print(f'\\n{sf} Hz: {df_sf[\"channel\"].unique()}')\n",
    "else:\n",
    "    print(f'\\n>>> There is only one sampling frequency configuration in your dataset: {df_ch['sampling_frequency'].unique()} <<<')\n",
    "\n",
    "# print('\\nSampling frequency configurations:\\n')\n",
    "# for i, (config, participants) in enumerate(sf_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Sampling frequency ({len(config)}) : {config}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49730cce-9c23-48da-afbd-2d63f0774c94",
   "metadata": {},
   "source": [
    "To inspect the participants ID in one configuration, run the cell just below after changing the parameter  \"configuration_to_inspect\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2cdcf25-4bc4-44db-abf9-b697c963f721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b9d53beffe463381b930ffa11e2305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='Selected configuration:', layou‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget to select the configuration of interest\n",
    "config_sf_slider = mk_config_slider(value = 1, min = 1, max = len(sf_config_dict))\n",
    "\n",
    "# print the configuration selected\n",
    "# interact with the slider output through the printing function \n",
    "widgets.interact(lambda i: print_config(i, config_dict=sf_config_dict, param=\"Sampling frequencies\"), i=config_sf_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e85239-2e34-429c-9ddd-192e2dab65a9",
   "metadata": {},
   "source": [
    "### 4.4 Inspect filtering parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08319a27-d470-44c1-b589-875cb7512049",
   "metadata": {},
   "source": [
    "Ideally with EEG sleep data, you want no lowpass nor notch filter, and a very low highpass filter around 0.05 Hz (to remove slow drift in long recordings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b553a505-1807-4ecf-bf4e-71b6b8782387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Filtering parameters are not fully consistent across the dataset! <<<\n",
      "\n",
      "\n",
      "Number of different filters configurations: 4\n",
      "\n",
      "\n",
      "Filters configurations: \n",
      "Configuration #1 (26 participants)\n",
      "highpass: 0.05, lowpass: 0.0, notch: 0.0\n",
      "\n",
      "Configuration #2 (1 participants)\n",
      "highpass: 0.17, lowpass: 0.0, notch: 0.0\n",
      "\n",
      "Configuration #3 (10 participants)\n",
      "highpass: 10.0, lowpass: 100.0, notch: 50.0\n",
      "\n",
      "Configuration #4 (43 participants)\n",
      "highpass: missing, lowpass: missing, notch: missing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if len(df_ch['highpass'].unique())+len(df_ch['lowpass'].unique())+len(df_ch['notch'].unique()) == 3:\n",
    "    print('\\n>>> All channels have the same filtering parameters! <<<')\n",
    "elif len(df_ch['highpass'].unique())+len(df_ch['lowpass'].unique())+len(df_ch['notch'].unique()) > 3:\n",
    "    print('\\n>>> Filtering parameters are not fully consistent across the dataset! <<<')\n",
    "else:\n",
    "    print('\\n>>> There may have been a problem in reading the filtering parameters. Here is the output: <<<')\n",
    "\n",
    "# Get the list of participants with different filtering parameters\n",
    "# 1st replace NaN because groupby does not like NaN\n",
    "df_filt = df_ch.copy()\n",
    "df_filt[['lowpass', 'highpass', 'notch']] = df_filt[['lowpass', 'highpass', 'notch']].fillna('missing')\n",
    "\n",
    "config_filters = (\n",
    "    df_filt.groupby(['lowpass', 'highpass', 'notch'])['subject']\n",
    "    .apply(lambda x: sorted(set(x)))\n",
    "    .reset_index(name = 'subjects')\n",
    ")\n",
    "\n",
    "# print filter configuration\n",
    "print(f'\\n\\nNumber of different filters configurations: {len(config_filters)}\\n')\n",
    "# print('\\nFilters configurations: ')\n",
    "# r=1\n",
    "# for row in config_filters.itertuples(index=False):\n",
    "#     print(f'Configuration #{r} ({len(row.subjects)} participants)')\n",
    "#     print(f'highpass: {row.highpass}, lowpass: {row.lowpass}, notch: {row.notch}\\n')\n",
    "#     r=r+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ded87ff-dd63-409a-b15c-a253213e9784",
   "metadata": {},
   "source": [
    "To inspect the participants ID in one configuration, run the cell just below after changing the parameter  \"configuration_to_inspect\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f080cb-0bf0-45ce-ac69-f72f8fe4edc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1753fcab0c8b4a439e595486b663480d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='Selected configuration:', layou‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget to select the configuration of interest\n",
    "config_filter_slider = mk_config_slider(value = 1, min = 1, max = len(config_filters))\n",
    "\n",
    "# function to rpint filters configurations\n",
    "def print_filters(config_slider):\n",
    "    # get the info from the dataframe\n",
    "    idx = config_slider - 1\n",
    "    sID = config_filters.iloc[idx]['subjects']\n",
    "    hpass = config_filters.iloc[idx]['highpass']\n",
    "    lpass = config_filters.iloc[idx]['lowpass']\n",
    "    notch = config_filters.iloc[idx]['notch']\n",
    "    \n",
    "    # print info\n",
    "    print(f'Selected configuration: # {config_slider}')\n",
    "    print(f'\\tFilters configuration: highpass: {hpass}; lowpass: {lpass}; notch: {notch}')\n",
    "    print(f'\\tParticipants: {sID}')\n",
    "\n",
    "widgets.interact(print_filters, config_slider = config_filter_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c8623-a3a3-4ebe-a94f-73faf82e6a7a",
   "metadata": {},
   "source": [
    "### 4.5 Inspect units in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed44982-de48-4222-a2e3-0ef7b323bae6",
   "metadata": {},
   "source": [
    "At the exportation, channels can be imported in different units. \\\n",
    "Each analysis software will handle units differently, so it can be helpful to know which units your dataset contains. \n",
    "- MNE python will automatically detect the units and convert the data to Volt. However, if the unit is not read correctly, the data will **not** be converted (e.g. \"UV\" is not interpredted as uV, therefore data are not converted to Volt )\n",
    "- fieldtrip is loading the data with their unit of origin, so you might want to convert all channels to the same unit before your analysis  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2ffc618-1e2d-48de-be65-d0f81c87be3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Multiple units were found: <<<\n",
      "\n",
      "\n",
      "Units configurations:\n",
      "Configuration #1 (26 participants):\n",
      "Unit (2) : ('mV', 'uV')\n",
      "\n",
      "Configuration #2 (42 participants):\n",
      "Unit (1) : ('uV',)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if len(df_ch['dimension'].unique()) == 1:\n",
    "    print(f'\\n>>> All channels have the same unit: {df_ch[\"dimension\"].unique()} <<<\\n')\n",
    "elif len(df_ch['dimension'].unique()) > 1:\n",
    "    print('\\n>>> Multiple units were found! <<<\\n')\n",
    "    print(f'\\n\\tNumber of different units configurations: {len(df_ch['dimension'].unique())}\\n')\n",
    "    print('Quick overlook of channels associated to units:')\n",
    "    for u, unit in enumerate(df_ch['dimension'].unique()):\n",
    "        # select only rows with the current sf\n",
    "        df_unit = df_ch[df_ch['dimension'] == unit].copy()\n",
    "        print(f'\\n{unit}: {df_unit[\"channel\"].unique()}')\n",
    "\n",
    "# print the different configuration of units \n",
    "# if info about sf configuration is needed\n",
    "unit_per_sub = df_ch.groupby('subject')['dimension'].apply(lambda x: tuple(sorted(set(x))))\n",
    "ch_per_unit = df_ch.groupby('dimension')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "# identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "unit_config_dict = {}\n",
    "for config in unit_per_sub.unique():\n",
    "    sub = unit_per_sub[unit_per_sub == config].index.tolist()\n",
    "    unit_config_dict[config] = sub\n",
    "\n",
    "# # print info per sf configuration\n",
    "# print('\\nUnits configurations:')\n",
    "# for i, (config, participants) in enumerate(unit_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Unit ({len(config)}) : {config}\\n')\n",
    "#     # print(f\"Participants : {participants}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a472b7c-c413-485b-8c62-73bcf20d2c00",
   "metadata": {},
   "source": [
    "To inspect the participants ID in one configuration, run the cell just below after changing the parameter  \"configuration_to_inspect\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b79f538-1c2b-45f8-8b0f-06874c4352f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa358a63b164621bf7839c7d1989c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='Selected configuration:', layou‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget to select the configuration of interest\n",
    "config_unit_slider = mk_config_slider(value = 1, min = 1, max = len(unit_config_dict))\n",
    "\n",
    "# print the configuration selected\n",
    "# interact with the slider output through the printing function \n",
    "widgets.interact(lambda i: print_config(i, config_dict=unit_config_dict, param=\"Units\"), i=config_unit_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01871a8-6bca-4642-8262-66c5737d43cc",
   "metadata": {},
   "source": [
    "### 4.6 Inspect signal inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1761b1c6-ac72-4c39-a8b6-f385dba0f0f9",
   "metadata": {},
   "source": [
    "Some softwares (e.g. profusion from compumedics) allows to invert the polarity of the exported data. It can be extremely confusing and can lead to wrong results. \\\n",
    "Here, we inspect if the signal is inverted by checking if the minimum physical boundary is higher than the maximum physical boundary. \\\n",
    "For .edf file, the physical boundaries are values that are set when exporting the data by specifying the scale of the data. \\\n",
    "\\\n",
    "In profusion (from compumedics) a scale of 1mV will lead to a min physical boundary of -500 uV and a max physical boundary of +500 uV.\\\n",
    "\\\n",
    "For other EEG format and software, the dynamical range might be set before recording (e.g. to be specified in the montage) and can't be changed at the exportation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1661b24f-eb0c-4787-ad96-538004d08ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Inverted polarity detected ! <<<\n",
      "1 channels have a inverted polarity (from 68 edf files)\n",
      "     subject channel dimension physical_min physical_max\n",
      "1442   27_N2      F4        uV       500.00      -500.00\n",
      "\n",
      "Saving informations from inverted polarity channels to:\n",
      "/Users/thandrillon/Data/Apomorphee/data/summary/inverted_polarity_edf.tsv \n",
      "(will be empty if no inverted polarity)\n"
     ]
    }
   ],
   "source": [
    "# select rows where the physical min is greater than the physical max\n",
    "df_inv = df_ch[df_ch['physical_min'] > df_ch['physical_max']]\n",
    "\n",
    "if not df_inv.empty:\n",
    "    print('\\n>>> Inverted polarity detected ! <<<')\n",
    "    print(str(df_inv.shape[0]) + ' channels have a inverted polarity (from ' + str(len(edf_files)) + ' edf files)')\n",
    "    print(df_inv[['subject', 'channel', 'dimension', 'physical_min', 'physical_max']])\n",
    "else:\n",
    "    print('\\n>>> No inverted polarity was detected <<<')\n",
    "df_inv.to_csv(f'{summary_path}/inverted_polarity_edf.tsv', sep = '\\t')\n",
    "print(f'\\nSaving informations from inverted polarity channels to:\\n{summary_path}/inverted_polarity_edf.tsv \\n(will be empty if no inverted polarity)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba40bd84-ccc9-4f33-b7a5-9cdf69c49860",
   "metadata": {},
   "source": [
    "### 4.7 Inspect theoretical resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc718a-33cd-45db-a431-39905dd59c3f",
   "metadata": {},
   "source": [
    "The theoretical resolution of .edf file is the minimum amplitude variation that can be recorded between two samples. \\\n",
    "Since .edf file is a 16-bit compressed format (meaning that a datapoint can take 2^16 value between a min and a max), we computed the theoretical resolution by dividing the dynamical range (upper/lower physical boundaries)  by 2^16. \\\n",
    "Ideally, resolution should be around 0.01 uV (or lower). \\\n",
    "\\\n",
    "Hence, to improve the theoretical resolution, we can reduce the min and max values of the dynamic range. However, reducing the dynamic range can lead to loss of data information (because the signal can't get higher or lower than the boundaries), an issue called signal clipping.\\\n",
    "\\\n",
    "Below, we detect channels that have a resolution higher than 0.1 uV.\\\n",
    "You can change the resolution threshold with the widget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5555defd-0390-4578-9808-21a28ffc3114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24337d711034c87896814bad6b0aeb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedFloatText(value=0.1, description='Resolution threshold (uV):', layout=Layout(widt‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# res_theo have been converted to uV, but if dimension was not read or not indicated in the headers, it might not work. I might need to add something more robust\n",
    "r_thres = widgets.BoundedFloatText(\n",
    "    value=0.1,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    style={'description_width': '150px'},  # augmente la largeur de la description\n",
    "    layout=widgets.Layout(width='230px'),   # ajuste la taille totale du widget si besoin\n",
    "    description='Resolution threshold (uV):',\n",
    "    disabled=False\n",
    ");\n",
    "\n",
    "# define a function to interact with the widget\n",
    "def check_bad_res(threshold):\n",
    "    r_mask = df_ch['res_theoretical'] >= threshold\n",
    "    bad_res = df_ch[r_mask]\n",
    "    \n",
    "    if not bad_res.empty:\n",
    "        print(f'\\n>>> Poor resolution detected! (>= {threshold} uV) <<<')\n",
    "        print(f'{bad_res.shape[0]} channels have a very poor resolution (from {len(edf_files)} edf files)')\n",
    "        print(bad_res[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "    else:\n",
    "        print(f'\\n>>> No channel with a poor resolution (> {threshold} uV) was detected! <<<')\n",
    "    bad_res.to_csv(f'{summary_path}/bad_resolution_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from bad resolution channels to:\\n{summary_path}/bad_resolution_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "\n",
    "widgets.interact(check_bad_res, threshold=r_thres);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e52b08f-3070-4184-b6ad-5c625401d1ce",
   "metadata": {},
   "source": [
    "### 4.8 Inspect dynamic range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f995de14-a19d-44cf-ab2a-53ae0a40e6d5",
   "metadata": {},
   "source": [
    "As mentionned above, a small dynamic range will lead to a good signal resolution, but can lead to signal clipping.\\\n",
    "Signal clipping happens when the signal reach the physical boundaries (min or max) and therefore is blocked at this value. It results in a loss of data information.\\\n",
    "\\\n",
    "Typical physiological EEG data (good quality) varies from +/-200 uV.\\\n",
    "Below, we check if the dynamic range physical boundaries are lower than 400 uV (+/- 200 uV). \\\n",
    "You can change the dynamic range threshold with the widget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6314a71-8c6d-4819-9ea0-0d3db1ee91ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df03a0523567430abac9842d039dace4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedFloatText(value=1e-06, description='Dynamic range threshold (uV):', layout=Layout‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dr_thres = widgets.BoundedFloatText(\n",
    "    value=400,\n",
    "    min=0,\n",
    "    max=2000,\n",
    "    step=0.1,\n",
    "    style={'description_width': '200px'},  # augmente la largeur de la description\n",
    "    layout=widgets.Layout(width='270px'),   # ajuste la taille totale du widget si besoin\n",
    "    description='Dynamic range threshold (uV):',\n",
    "    disabled=False\n",
    ");\n",
    "\n",
    "\n",
    "def check_bad_dr(threshold):\n",
    "    dr_mask = df_ch['res_theoretical']*pow(2,16) <= threshold\n",
    "    bad_dr = df_ch[dr_mask]\n",
    "    \n",
    "    if not bad_dr.empty:\n",
    "        print(f'\\n>>> Small dynamic range detected! (<= {threshold} uV) <<<\\n')\n",
    "        print(f'{bad_dr.shape[0]} channels have a small dynamic range (from {len(edf_files)} edf files)')\n",
    "        print(bad_dr[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "    else:\n",
    "        print(f'\\n>>> No channel with a small dynamic range(< {threshold} uV) was detected! <<<')\n",
    "    bad_dr.to_csv(f'{summary_path}/bad_dynamic_range_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from bad dynamic range channels to:\\n{summary_path}/bad_dynamic_range_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "\n",
    "widgets.interact(check_bad_dr, threshold = dr_thres);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180ef60c-378d-430c-a695-a4b578766441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
